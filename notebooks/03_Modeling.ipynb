{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the name like rex not ash nickname little vide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probably the demand insane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these image emanate 2006 2014 and 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not having all the crazed medium attention act...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  target\n",
       "0                                           removed        1\n",
       "1  the name like rex not ash nickname little vide...       1\n",
       "2                        probably the demand insane        1\n",
       "3            these image emanate 2006 2014 and 2020        1\n",
       "4  not having all the crazed medium attention act...       1"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cleaned comments data from csv\n",
    "df = pd.read_csv('/Users/annamitchell/Desktop/GA_Docs/Projects/NLP_Project_4/datasets/comments_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed   -->  sl\n"
     ]
    }
   ],
   "source": [
    "import langdetect \n",
    "txt = df[\"body\"].iloc[0]\n",
    "print(txt, \" --> \", langdetect.detect(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5477, 2)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3772\n",
       "1    1705\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5477 entries, 0 to 5476\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    5477 non-null   object\n",
      " 1   target  5477 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 85.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sent & word tokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the name like rex not ash nickname little vide...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probably the demand insane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these image emanate 2006 2014 and 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not having all the crazed medium attention act...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lame</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>look like bought some hair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>itt most people think take this shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dude whoa feel out the loop when did the last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>would say most like howard hughes robert house</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  target\n",
       "0                                           removed        1\n",
       "1  the name like rex not ash nickname little vide...       1\n",
       "2                        probably the demand insane        1\n",
       "3            these image emanate 2006 2014 and 2020        1\n",
       "4  not having all the crazed medium attention act...       1\n",
       "5                                              lame        1\n",
       "6                        look like bought some hair        1\n",
       "7              itt most people think take this shit        1\n",
       "8  dude whoa feel out the loop when did the last ...       1\n",
       "9    would say most like howard hughes robert house        1"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.688698\n",
       "1    0.311302\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['body']\n",
    "y = df['target']\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       body  target\n",
       "0  removed        1"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.columns[2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       body  target\n",
       "0  removed        1"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = \"target\"\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(x, fontsize=12)\n",
    "df[x].reset_index().groupby(x).count().sort_values(by= \n",
    "       \"index\").plot(kind=\"barh\", legend=False, \n",
    "        ax=ax).grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4107,), (1370,), (4107,), (1370,))"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "text.ENGLISH_STOP_WORDS\n",
    "\n",
    "add_stop_words = ['did', 'doe', 'don', 'doesn', 'getting', 'going', 'got', 'ha', 'isn', 'wa']\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---->>> getting errors on my fit call in my Count Vectorizer so I am commenting this out but leaving in case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CountVectorizer with the default hyperparameters.\n",
    "#cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on our corpus.\n",
    "#cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the corpus.\n",
    "#X_train = cvec.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train into a DataFrame.\n",
    "\n",
    "#X_train_df = pd.DataFrame(X_train.toarray(),\n",
    "                          #columns=cvec.get_feature_names())\n",
    "#print(X_train_df.shape)\n",
    "#X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test\n",
    "\n",
    "#X_test = cvec.transform(X_test)\n",
    "#X_test_df = pd.DataFrame(X_test.toarray(),\n",
    "                         #columns=cvec.get_feature_names())\n",
    "\n",
    "#print(X_test_df.shape)\n",
    "#X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemming ---\n",
      "['r', 'e', 'm', 'o', 'v', 'e', 'd', ' ']\n",
      "--- lemmatization ---\n",
      "['r', 'e', 'm', 'o', 'v', 'e', 'd', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(\"--- stemming ---\")\n",
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "print([ps.stem(word) for word in txt])\n",
    "print(\"--- lemmatization ---\")\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "print([lem.lemmatize(word) for word in txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the name like rex not ash nickname little vide...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>4.710526</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probably the demand insane</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these image emanate 2006 2014 and 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not having all the crazed medium attention act...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  target  word_count  \\\n",
       "0                                           removed        1           2   \n",
       "1  the name like rex not ash nickname little vide...       1          38   \n",
       "2                        probably the demand insane        1           5   \n",
       "3            these image emanate 2006 2014 and 2020        1           8   \n",
       "4  not having all the crazed medium attention act...       1          11   \n",
       "\n",
       "   char_count  sentence_count  avg_word_length  avg_sentence_length  \n",
       "0           7               1         3.500000                  2.0  \n",
       "1         179               1         4.710526                 38.0  \n",
       "2          23               1         4.600000                  5.0  \n",
       "3          32               1         4.000000                  8.0  \n",
       "4          60               1         5.454545                 11.0  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'] = df[\"body\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "df['char_count'] = df[\"body\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "df['sentence_count'] = df[\"body\"].apply(lambda x: len(str(x).split(\".\")))\n",
    "df['avg_word_length'] = df['char_count'] / df['word_count']\n",
    "df['avg_sentence_length'] = df['word_count'] / df['sentence_count']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.columns[6], axis=1, inplace=True)\n",
    "#df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Average Word Length')"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "sns.distplot(df.avg_word_length, kde=False)\n",
    "plt.xlabel('Average Word Length', size=14)\n",
    "plt.ylabel('Count', size=14);\n",
    "plt.title('Distribution of Average Word Length', fontsize=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.587028830431512"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"avg_word_length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv4AAAIGCAYAAAAspIvNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdebgkRZ3u8felGxAE2UFWG7UVcEPsAdywBUVAHdBRB1EBl4sLKjo6XnScEXW84+6IC4qCjQsiIzigog6yuIM0imwt0AMN3ayN7MjO7/4RUZ6s6lqyTtdyquP7eZ7znKqoqKzIrMyoX0ZGRjgiBAAAAGDVttq4CwAAAABg+Aj8AQAAgAIQ+AMAAAAFIPAHAAAACkDgDwAAABSAwB8AAAAowCof+NuOyt/8cZdnGGzPr65nl3wHV/ItGWERx8L2EZX1PXvc5VmV2X607Q/b/q3tv9h+oLLtLxh3+QAAmKlsn1P5zTx8mJ81e5gLb8f2EZI+1CXLA5LulfQXSddJukzSQklnR8SlQy8ggL7YfpakH0naYISfuaekn7UkPyEirhhVGVAe2+tLOkDSfEk7StpE0rqS7pN0u6Qlkq6QdL6kcyQtjIiHx1FWoB3bb5F0VCVp84i4YVzlwejNxBb/1ZUq0jmSniXp9ZK+JOkS25fYfqvtNcZYvq7qtr6jPtsLKtt0wbjLgym215R0opqD/ksl/VwpMP+ZpN8M4aPfUDMNWGm2V7f9L0qNUV+S9EpJcyWtL2mWpLUlbS7pmZIOlPR5SedKWm776WMp9JDYvqFSH+8/7vIAM8koW+6na+Qt/m20ttrNVqpM15f0GDWXcQdJX5b0btuvi4hzR1NEAB28WNKW+fHDkl4QEWcN8wNtbyhpvzYvHWj7gxHx0DA/H2XJJ7cnS9qn5aX7JF2udHV6NUkbKZ0MVBumNpS03giKCQC1jD3wj4i9Or1mey1JO0l6hVLLf6MCnSvpl7ZfHBE/77F8D6qsM1VEnC1plV/PfkXEEZKOGHMxVnU7Vx7/ethBf/YaSWvmx3+UtIWkzfL/vZW6HQGD8nE1B/1/lvSvkn4YEfdVM+ar0TtJ+ntJr5L0uFEVEgDqmIldff4mIu6JiN9ExLslbS3p25WX15B0ku0nj6d0AJRaORuWjugzq116jpX0nQ6vASvF9taS3lFJWijp7yLi+61BvyRFxP0RcU5EfECpgWpvSdeMprQA0NuMDvyrIuLOiHidpE9Ukh8l6egxFQlAuien4cFhf5jtZyjdVClJ90v6rqQFlSwvsb3psMuBYuyr1Ie/4T0RcVedN0by04i4cjhFA4D+TUzgX/Evkn5def7MPMJHW/0M52l7vXzz8A9tL7F9l+0Hbd9p+yrbZ9r+tO19bK/e8t4F+Wbes1rSo8PfgpZ8bW8Ktr2F7ffZ/o3tZZVhEuf3em9dtufa/rjtC/JQjH+1fYXtr9neteYyzq6U4Yia7+k63GZlfQ6qJB/UZZvO72f5Hco0y/arbH/b9uW2b7d9j+2rbf/U9mF5ZI86y2p7U7Ltp9o+Mt+sfrvtu/P2/voobgS0/ez8+Rfavtn2fbavt/07pyE5H9/j/X/7rtX7u1ky4OJXW/R/FBF/iYiLlLr8SOlE5HW9FmL7Y5UyLrVduy60/cSWdXxBj/yPtP0m2yfZXmz7jso+9UPbb7b9iBqfu13L5z46p29s+522z8rLvM8dbry0/TinOu47+Xi/Jdcpd9i+0vb3c3nWqrs9KsuebfsN+Ti5NpfjWtu/tP2OxnHTaT1qLH+jvJ6nOdXHd+Vj50rbJ9p+je1ZvZfUl+0qj0PS7wa8/Ca2n5+PzQts32T7/vz/93mf7XpsVpbT9gZD27vZPs72ZXnb3W77Ytv/aXvbLsvbq3LMb1Z56bttjvmwfe+krmuXz7HtvW1/KZf5xlzmO51+K07O+/kWNZc3kHphpsnH9xGeilnutX2r7UttH2X7eTWX8/HK9/rTSvpc259w+v261Sleucr2t2w/dxrl3cH255x+j+/If4tsH+M0Yl0j3wmV8nylzTo3jo9dKi/9R4fjo596b6D7sSQpIkb6p9TnOhp/01zGC6vLkPSDLnmr+eZ3yfdSSTe15O/298mW9y/o470haUHL++e3bhelYeNu7/D++d3e22EdD67kW5LTDlW6Sa1TOR9WuqF6do/v5OzKe46Yxr5wdo/vrs7f/H6W3+bz/k7SRTU+52ZJr6+xvOo+sUCp5fDfJT3UY3t/aEjH3qaSTq2xfvdL+kyn77zlu+71t2SA5X+EpFsry/77ymuHVdIvqbGsJ7aU8wV9lONjlfctlbRaj2PuhhrbaamkPXt87nYt73m0UleSGzssc/+W9/+qj+/tJkkv7mOb7FDj2LlGaaS2Fdajx7It6X3qXBdW/y6VtNMA97lvVpb9sKTVh3RsblfzuLpf0qckzeqxvHMq7zlc0jqSjuux7Hslva7D8vbqY98JSfdO6rp2+IxnKTUu1Fn3ByU9p8fyDtaA6oVp7GtvafmMrsdfH8t9lKRj8vr3Wq8fS9q4x/I+Xsn/05z2T+oer4SkL6pLndzyGR9WGkK+2/K+pHRP2QmVtK+02af7OT5W2O6j2I8bf2O/uXc6IuJ021dKemxOep7t1WKa4yU7tRSfrOabnW9RGo/5TklrKbVyPFZTV0laWwgvUhqhaEOlALKhddSiav5uZXq5pvouh6RFSj/wG6q5FWrabB+idJBI6WC9WNJtSvdTNG5Ks6S3StrI9qunu42nqbHtnqJ046aUhtPrtO1ume4HObXa/rekR1aS71YKJO6V9Hil4fqk1K/9WNtbRcRH+/iYLypVupJ0l6RLJN0jaVulEayktL2PsH19RAysG5vtbSSdobQeDQ/lMtyiNDLP3Jy+ulIFu73tl8WKfZl/r7RNpN7fzY0DWYHk5UqjfUnSckmnVV77jlKQsLqkHWzvGhHndFpQRFxm+1xNtc4cqDQEaVe2Lem1laRvdzombH9a0ntakm+QdKXSj80cTX3vW0n6se3XRsT3epUj201pvRv11uVK38F6Sic2rapXkx7O5bhJ0l/ze7ZTGkpZSuPTn2r7VRFxUrdC2H6i0pXOaherB5Tqk9s1tW9tLel/VOOKTGXZq0v6lqR/bHnpak31nZ+rdBIkSdtrauCHX9T9nC5urhZHqdHptA55p8X2bpJO0dS+LaXj61Kl+nhDSU9W+p5Xl/ReSXNtv7xmfTxb0g8kNa5M/UVpX3lA6TtvfG9rSjrO9tJIA0ZULddUffx8TY1c9CelfbrV/e0KMiHr2lrm10n6uppHa3pY6Sbvm3L6NkrHsJQaeNbpsrxh1wsjZ3tLST9R+j1oaGyjG5ViqCdrarvsI+m3tneLmnMIuHkOqHuV6pc7leqV6u/aoUrfy0d6LO/zkt7ZknydpMVK+8cOSvXh23L5u7lLU8fHrpoaiOZySVd1eM8K9whVDHw/bjLIM8maZ1hHqHLGshLLaT0TelqHfNU88zvkqZ7JXy5pd0luk29tSS+RdLyk/+iwrPnTWb/W90m6I/8/WmmCjWreDSVt2O9nqrnF/06loDMkfVXSJi15d1Qah7papsO6LPvsSr4jprEvnN0l34JKvgXT3Ne6LX8LpQOrkfcepcB37UoeK7WuLmnZJi+pWe7l+f/NSt1j1mjJu4eaW25vk/TIAR1zs5TG0q+W++uSNmvJt4NWbIn7dI9lT+u7meZ6nFH5rM+1ef2/K69/rcby3lbJf1ed7a0U9FS3z/Yd8r2rJd+P1KYlWtIzlLqPVMuxXYdltrYqNeqIEyVt25J33Tbf7/VKE/e8SNJaHfaTfZROBqv74SZdtsdspRteG/kflvRpSRu05Nte0pk5T+uV1Y4tjpL+syXvcUoTtbXm210pyGjku65bufvY517Z8vlXS3r6APfpOWq+irVM6cSytX7YQOnE9uFK3g92WW619bBR9yzO3+9qlXyNE9l7Kvkv6lHmakv1/qv4uj5PzS3Yd0j6v6r8/lbybiHp7UonMXuNql6Yxj430BZ/pRO0aqxwr6QPtm6jnO9Nmqq3QtLpahNr5fzVFv+b8/5wV97Ga7Xk3VnpxKmR/z61xE0t+fdr2QaXSdq9Jc8jlH4j7tKK9dZXuiy7qeW+j+04tP14hc8axI7U505yRHWDr8Ry3tHyxb28Q75qnvltXt+q8vrDavOj0mG5bS8/anCBf6h+AF3rM9Uc+Df+Ptkl/yMlnVfJe5ekjTrkPXsa5a7uC2d3ybegkm/BNPe1bss/vpLvIUl7d8m7tdIPViP/tepw+V8rdv+6VdITuyz7OS35+76E12G5h7Qst+1Ja867hlJlXD0mnjLo72Ya67CtmgOBFU701VyZ36EegbzSCXT1svGBNcrxjUr+czvkmduy3F4nT2uquRvOSR3ytbuc3PEHqM3716mZ71GSLqx8xr92yft/Wsrz3i55V2/Ztxp/bQMPpaCrmu8dPcq9gVLDTSP/Zwaw3z0iH+PVcjysdOXibZKeqh5dUXos/6zKchepx8mKUmtmI/89kjbtkO+cljJfri5dK5QCsmr+v+uSd7qB/0Stq1JduLSSb7k6NDC2vM+qNBpV0odSL0xjnxt04P+hyrLukrRrj/zPUHPQ+tIO+T7eUs57Je3cZbnbK11pauT/5w75ZimdwDfyXdlp38r599CK3XOHHfgP9Jht/ZvEm3sbbm55vuE0l7N15fFNEXF5nTfF8CcJukRSP91IpuMKpZul24qIuyW9UemHTkonAgcNuUwjZXtzpXkiGr4aET/plD8ilqr58uAWSuN11/G+iLisy7J/reabB/u+UamDankvUhqDvFMZ7le6gfavOcla8XLoOLxeU3NV/Cki/tQmz481VS+sq9Ra21FE3KLmMf8P7Jbf9tqS/qGS9M0OWd+jqW4BCyX9c49y3Kfm42w/p2Eke7lO6cpULVF/NJo71FwvvLxL9rdWHi9Uujek03IfUPqxatsNpI33Vx6fHBFf6JY5Im5tKc+bVvbmyIi4V2m/eKCS3Ojy8yWlri532P5tvkHw5bbXbbOoFTgNnDA/P31Y0qsjYnmP8nxJU4NbPEJpe9bxxoho/c2sWqAU2DYMqu6RNLHrepCmuu80ltuu3mkSyV/bvDSqemFkbD9Szb8P748uXSwlKSLOV7oq2PCOTnlbfCwift9luYvUXJ93+l5frNQ1q+GdEXFTl+WeIelrNcs4SEM7Zic58L+15flGbXP1dk/l8aa5r9pM8PURnFx8Nf8YdxQRF0qq9pX9h055J9RL1Twk5Wd7vSEiTlZqJWh4WY3PuUudA8Wq6rZ+Uo38Xdl+QstyPh8RXYfdzCc31f6k7WbJHRmnEXcOriQd1y5f3pe/W0mqM6Z/9Tt5vu2tOuZM33MjqLtf6Wav1rLOVppgrOGzkZtnuskNDo0fzNWUuhT18q0OAcYgVE9An+I2o/zk0Uuq9w18pde6RsTVkn7Y68PzCfmLKkmf7pS3ZflnKJ0QSenKxc5dsteSl7mbUneAdtaW9EylbhwnSbohj8Lx2A75Gw6uPP55RFxQs0jVfbbriFLZRRHxq24Zcp3wm0rSStc9LQ6uPJ6Uda0ex+dHxKk1Pr+tEdcLo/RSTTW63qH6AXL1e32u08R33YRSN8Ve6vx+vqTy+BqlBqNevtg7y0AN9Zid5MC/dabangdRB5cq3cTZWOaPbP9dl/yj8ssRfEbHlu0W1QNjJ7cMZTrhnll5vCgiFtd8X/VH4Jkdc01ZGG0m/GljWeVxrWFDe2gtW8+gKzul8nhj23M75hy+PTV1Ze5BNU/Y1WpB5fFza5T7NE21mqym5ht3W1WvCPw4Iv7SJs8z1HxjX88bhisurDyeVyP/tOoI26vZfq7t9zgN2ftfTkNk/rTxp9T9rWGWpm6erdql5fkZNYtwZo08u1Ue362p4KeOfrdjT7kV80mS9lfaZ7ody2sr7SuLbL+lS77nVR4Pcz/5Te8skgZf91RN1LraXlPN+/eJNZfbySjrhVGqfq+/zlfIeoqIKzQ1QMQjlG787eayHq3fDXX24er3elbNE7CLlfr4j8pQj9mJHNUna13Jdj/CPUXE/fnu7g/kpB0l/d725Up3af9G0u8iYtSzLw570pcH1LkFq1V1pJZHKAVhq8qkNNXRAHpexq2oVsZb2F4rIu7pmLv9yBft3F15vHYf5emkun43dLuk2eLCluePV+oaNg7Vlvuf9Lgs+wfbF2lqdIk3qLnLSGv+B2yfoKnLza9T6lvaJLdA71FJanvVQanP998WL+lbaSCgWqoj8WxSI39fx2C+cvImSf+mNNJOP9r9qDym8vieiFhSc1mX1shT3Y6W9JM+tuOOlcd1tmMt+Qrs9yR9L3ch2llpBLenKwUTrePOryHpKNsPRURTS2huPKmOzvZa23uonmoAua7tNXs0Koyr7pE0seu6rdJvXcN5NZfbySjrhVGqrtdTXRlvv4bqnBu91muQ+3C13lpUc7mNvKOaHHKox+wkB/6tX8C0h3JUujllSzX3X39C/nuHJOXhQ09W6oJTN2BeGXcMefm39dGVqPWkaoNBF2aMquvStc9pi9a8G6i521irOq39rWr/MnQxyPUbOdsbKc2e2rCgxtuO01TXkANtf7DHvv5NTQX+O9ieFxELW/K8VlM/VDer85CO1S6HVnN3lX6s1ztL/ToidzX4tlYcFrOuNdukVU8Gbu9jWa3dNNupbse1Ndzt2LfcsvlLVa662J6j1KXlXS2f+5+2T42I6tC2rV1Tn6rmIKof66l7a+S46p6GSVzX1nsGV7a1d5T1wihV12srNd8T0Y9e6zWQ7zUPx1y9B+e2PpZXp94alKEes5Pc1ae1O07dLhoriIgHI+JgpSHhTlH7jf5YpTGFL3Waua/dD+HAxPDHy697g5204vYY6rqPWHVdVmabzNQZFqe7fq2XbMe1fq9V8/jZX3eabbjjn1KLdsMWSsOwdpSD/EsqSe1u8q2OPf/dLvfGPLJDer/q1M391BHvUXPQv0hpUqznKl3BW0dpdBpHhNV73OpW/XS1rPMDNcrtOBARsSQijlAKaqtXY9ZWcx93aXDrJ8383/FJXNfW+m46gVjVxO3PNU3aeq1MF/FBngyP1SS3+D+78vgvSpM5rJSIOEvSWflGtmfmz9hNaZjFRkWwmtIwbhtr+q1nM0GtkSeyR7U876d1r5tZvbMMXfWMf2W2ST8tB6M03fVrbYEZ1/q13qA7nSsPb1DzaA/tfEtTXXz2t/1PjZugbe+o5olpOnXzkZq3040RUWta9mHKrf2HV5JOUhpVpduN/XX2leq69tMnvE7e6rLPjYhd+1j+WEXENbYPVfM9VM+V9InK89bjae+I6KebxCSZxHVtbd1d2Zb2GVcvDMhtmmrl/0REHN4t87hFxMO279TU99nP78mg73sZm5l29liL7b2UJgNp+EWdGzTqioh7IuLMiPhoRLxQKch/vZpvpHiV7WcN6jPH4FG26w6B2jo6RbvLntXW5Lo3/86ELkPVdXlcx1wrqua9XzM38K+u32NyEFhH67YY5Y1NkqR8k/10uwRUvcR2r76Z39ZUC/omar5KUL0CcGkejq6Tat/MzWzPhEvzu2rqRyuUJuLrOpqXmoc57uTqyuO1cleXOnaokae6Hee6jw7RM8Tpaq4Tt2h5/ZaW158w9BKNzySu6/Utz9vNhN2PmVgvDEJ1vSbhe5Wa663t+3hfP3lntIkL/G3P0orjkH95mJ8ZEXdHxAKl0UWqP5jt+uk1XX6f4T9YraNy1Ml3TYfxl6v9jeueUDyldxZJzdt00NuzGsTN62PEoupJ3x9H0DVruqrrt6aknWq+r7p+D0mqO/zeIFVb+5c0uqHU+VNa10ar3epq7qqzgoi4Vs2j0hwo/a2+OaCS3q21X5J+2/L8hT3yj0L1ZrZr87r28pwaec5teV73hs3da+SpbscNlUZFmRj5npLqUKsPtrweah6paM9RlGtA+qqPJ3FdI+IGpVnaG+av5CJnYr0wCNX1ev6EjPhXrbeeXydGs/1k1b+xd5jxykBMXOCvdLm0GpT8Oo+zPHR5gojqXeDtLtfd3fK8376yo/TqXhny+LrVCa5+0SFr9Sy6ZyttHiWl7uX76jYd9Pasrs96kv6+1xtst7YId9omM8Hv1dxfv2sAXFFt5T4/ak7+NCi5u111//xep7ztRJqI7AeVpH7H9H+p7fWVTu43y2kPK10Z6Pa5V6l5tKy6k9MMU18/xvmHsOf2iojrJP2xkvSWXj+ith+jNPZ3L79Vc2PCTNiOtdneTM1dA65rk63aFehFYx4ytx/TqY8ncV2r3ZH2z/XBtMzQemEQqt/r+uo+HPJMUe32uY3ShF69vL2P5Q8zXhmIiQn8ba9r+ztKN6k13CbpzSu53H7PyKrDi7UbSaj1EuFMruAOsP20HnnereYTnGM65KuOgrKr7W065Gv4qJpv2uymuk0HvT3PlPS/lecfqzHb58c1VfaQ9PUBl2lgcsBendTqENvbdcovSbZfp+aJmY4eRtl6+Ac196vtK/Bv854d8uyh3Zws6c78eE2le3iqJ0A/z8FuL5+qPN6tx1juo1At81Y1JpZ6q6Re9UJDdVKdeWqun5vk1sCvq8Zxn4dsPLKS9Frb+9Qs08DY3r1GXdbOu1uetxu3/auaOrmZLemYCWkxnU59PInreqSmbv5cV2mm5pUx0+qFlZbnt6hONPXxaR4vo/RjpYm7Go7s1hU0Dz37f/pY/jDjlYGY0YG/7bVsP9v2ZyUtVfMl9/skvTwi6owJ3c1rbH/Pds9JmGy/Tc393c9qzZMDg2q/t3fl7gIz0SxJp9huHX9akmT7FZL+vZL0q4jo1Lr9Y00NZ7mapK+2q9id/KvSVOR1VburPM12nRkca8mXoT9SSXqipP+yvU5r3lz2D6i5NfQ7eTKSmewTmmr1X0Npkrq2wZ/tFyr9SDdcoe4TZg1Ldf+4PCL+2DFnZ2eoeVjSrvtcngX3pErSW9R8BahXN59qvuq431+0/c+96gHba9t+re1+Jquq47dqHpXkqE6jkuWTvs/3sexvqPn4/KTtT9luun8nn2z+VGn21brDyn5GU90tVlM6Lg/qnP1vn7W+7UNt97qhu459JC22fazt59S4ojE71xHvqyTfpjYnrhFxq5pHoHqu0nwFm/cqlO2dbX/H9jhmUq9+3wfUKe8krmu+wl9t1DnA9jHtfhsabM+yvb/tdle9Z1q9MCjv1dQ9HJtK+oXtnjNm255j+z9s/8dQS9cid8M7rJK0raRf2m6aFdn2mrbfqjTS42pKwzjXUT0+XtyroW0cxj6qj1ec8GGWUkvf+kpfSLsyni/p4Dyb2sqaLelVSjfrXq304/QHpRONO5Qu1TxB0svUPGX4b9V59r1vKx0MUhrGbR+nSYWq3SXOjIgjW984QsskXaVUAf/J9teVWr9vVbqx7xWS9qvkv0tp8p+2IuIO21/WVIvfXpLOz2mLlALOJyu1oO6o1LL6P0otu72cqXQWvblSn7nTbV+i1L2oes/FB6ezT0TEN22/VFNdml4i6RLbX1O6knGf0j5wkJpnwl2iCbhkGxGX2f5nSV/ISY+TdKHtY5WC41uVbj7cT+lYaAQ390t6bd3ZGAcln5RUZ4ScTmu/IuIh2ycpBfCS9I+23xURrd3xqo7T1NCL1Ymg7lRz16Fun/ug7Zcp9SXdUqlO+6Skt9n+nlL3q5tz+gZKN43trFS/rK2VHzqwtTx32f6qpHfmpD2VjvmjlCZqs1LL1P6a6sv8FU1tt27LftD2a5TGs980L+u9kg7Ldd7tSvtW4+bIu5Wu0p5cWUzb9Y2I22zvq9Si+CilbbPA9nuVTtD+qHTVdQ2l8cSfpNR98PlK3ZsGNd/K6kqDO7xe0tW2f6H0HS7Lnz9bqTvYM5TqkDnV1ZD0jg73RSkiPu80atTBOWkPSVfa/r5Sw9JSpQaV9ZTq5Z2Uvr/GfRt1Z+IepO8ozVUgpa4SV9n+g9I+3ejffH9EvKr6pgld13cqfa+Ne6PeoBTMHa80uedypf1vG6V74fZV2hf2VsskiDOtXqhY0mfHhxsiYk7jSUT8Pl+9OEbp+J8j6VzbpyvNd3KZUiy1jtK2eZpS/d64b6fa0DQSEfHfto/UVJ34REln2r5WqQfAGkr1SWN0s28ofQeNkRy7fRf/pfS9rpHff7HtPyo1CFfnkzk4IsYzKEhEjPRP0hFKleF0/n6jVPnO7uPzqu+f3+b1g6dRjgskbd7lM9dVOnnotowFLe+ZX329z21a670t67pEqfL53xrre5ek3WqUY22lm7jqLG/vln3h7B7L3lMpaOi23Pkt7+ln+WsqTctedx9YJGmbHstc0On7rvsdDfjY+yelH+Y663eHpD1qLLPvdayxzH9vKcsOK7Gs57Us6+Ae+Z2Pjdbtccw0PnsLpQaCfuuXezssb7uWfI/uoyxrK7U21vn8U5R+pKtpu/ZY/g5KM3x3W+5SpfuzdmxJn9Vj2dtJ+vM0tuOfB7AvfmIan9v4u13pxLnXZ1jSh1X/2Kz+7d9hmdV6+PCa6/rxynt+2ucxWncfnsR1fZRSX/Z+yrrXqOqFaezTb1mJfTqUAv92y9037/P9Lu8rK/sdVd6zVz/bS+lq/wM9yvdlpfjgvytpH+mx3Dcr3dDfbbmPbnnPUPfj6t9M7Opzj6QblboY/FrSF5Uu0T8hIp4dEd+IPL72gJyptPH+pN4T4lwj6f2SdomI1r78fxMRdyq1DL9ZqcJYpu6zuo5FpNE9nqE0hnm7yZ1CqVV+x4j4ZZvXW5f3V6XRCr6illEsKs6WNC8iftLh9U7L/h+lUYA+qdRicouaW/tXSqQ+xf+o1OrZbRrvvyjN9PyMiLimS74ZJyI+q9QqdYY67+v3KrV67xAjumm+yvZqap5B++JYue58v1JzH/euN61Gqk2/1ealb7ZJ6ypSt7/nKt3wVqer0qVK+/fAR7DJx+Z8pT75nSZyu1apJXc/dT5+Oy3/UqVW0TcpDWV5ff6c65Xq8cMkPSUifqupm6Ul6ZboMYN4RPxZqZXwUEmX9yjKw0qNLh9Sj4nbavqA0hWEz1Rqv6IAACAASURBVCk1+NSZ7XypUn/uJ0ZE15vBpbTPRcSHlNbxBPX+rfiL0lWwl6m5a9rIRMQHlfan45T22ztUY0K5CV3XO5S6fP2jUpzQzQ1KXeX+0GV5M6ZeGKSIOEXpyvin1LtbzL1KPSbeouY5RkYqIv5NaV88Uqlx4a78d5mkYyU9JyLeluODar3VtbtiRHxVaZLZo5T2mdtVr+4YCeezBijdQKzUGvVYpbG811Iaku1GpS/v4lhFN5jTmP7zlSbjeITSD/Yvphvc5uXtrnQJdLZSUPG7iLiy6xtnCNtPULrMuqnSJbvlShXwuTFzh+6szWlkot2UWp/WVTqRWiLplzlIxIA5jfTyLKWb5TdQCq5vU7rqdnFE3DiicmykdKzPUTo2b1QKqH83ivrN9r8ptfpK0hkR0dc9O04jA+2s9EO8vlIQcYvS7O0XRepPPhT5N2J7SY9X+o1YR+l7vFOpjrtI0lUrsx3z/Re7KnXJ20ipq1Fj+YskXbYq1EHSZK6r7a2UjuPNlLol/VWpceEipXk++vruZ0q9MEj5XpinKTXWbaR0nNytNB/MZUrrNdIupCsj76e3aWoi1+dGxK/HWKSVQuAPABgJpwnkLle6f0uSPhwRR4yvRADQne03aupG73skbTzJDWQzsasPAGBC9BrppsVnNBX0P6x0jwgAjFTdeiuPeviJStJ3Jznolwj8AQArZ0vb59t+S+4GsQLb82z/UFOjaEjphuklIykhADT7nO2jbM93+6HHH2X7UKVBETbKyX9V80nARKKrDwBg2nKwv7SSdIPSUMF3K/XtnaupH86GC5RunOs2tCoADEUewrwxt8v9Sl0QGzclb6o0xGd1joWHJb0+Ivoe6GGmGfs4/gCAidZ68+Wj1Tzbd1UozST9ZoJ+AGNUrbca8wx1cq2kt0TEICYFHDta/AEAKyVPuvZSpdFJdlCaI2RdpRFKbpV0pdIkX8fHYCZeBIBpyyP1vEBpIrlnKN17tLHSScCdSiP5LVQa0vy7eUjPVUIRgf/GG28cc+bMGXcxAAAAsIo7//zzb46ITcZdjnaK6OozZ84cLVy4cNzFAAAAwCrO9tXjLkMnIxvVx/YjbP/e9p9sX2L7wzl9W9vn2r7C9vdsr5HT18zPF+fX51SW9f6cfpntF41qHQAAAIBJNcrhPO+TtHtEPE1pdty9bO+qNDTS5yJirlJf0MZd1m+UdGtEPF5puvRPSJLtHSTtL+lJkvaS9GXbswQAAACgo5EF/pHclZ+unv9C0u6Svp/Tj5O0X368b36u/PoeecKFfSWdEBH3RcRVStO07zyCVQAAAAAm1kgn8LI9y/YFkm6SdLqk/5V0W0Q8mLMsUxoNQvn/UknKr9+uNBb039LbvAcAAABAGyMN/CPioYjYUdJWSq3027fLlv+3m045uqQ3sX2I7YW2Fy5fvny6RQYAAABWCSMN/Bsi4jZJZ0vaVdL6thujC20l6br8eJmkrSUpv76epFuq6W3eU/2MoyNiXkTM22STGTmiEgAAADAyoxzVZxPb6+fHaylNnLBI0lmSXpGzHSTplPz41Pxc+fUzI006cKqk/fOoP9sqTQf/+9GsBQAAADCZRjmO/+aSjssj8Kwm6cSI+JHtSyWdYPvfJf1R0jE5/zGSvmV7sVJL//6SFBGX2D5R0qVKs0IeGhEPjXA9AAAAgIlTxMy98+bNCybwAgAAwLDZPj8i5o27HO2MpY8/AAAAgNEi8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKMHvcBVjVHX/uNX3lP2CXbYZUEgAAAJSMFn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABRhZ4G97a9tn2V5k+xLbh+X0I2xfa/uC/LdP5T3vt73Y9mW2X1RJ3yunLbZ9+KjWAQAAAJhUs0f4WQ9Kek9E/MH2upLOt316fu1zEfHpambbO0jaX9KTJG0h6ee2n5Bf/pKkF0paJuk826dGxKUjWQsAAABgAo0s8I+I6yVdnx/faXuRpC27vGVfSSdExH2SrrK9WNLO+bXFEXGlJNk+Iecl8AcAAAA6GEsff9tzJD1d0rk56e22L7R9rO0NctqWkpZW3rYsp3VKBwAAANDByAN/2+tIOknSuyLiDklHSXqcpB2Vrgh8ppG1zdujS3rr5xxie6HthcuXLx9I2QEAAIBJNdLA3/bqSkH/dyLiZEmKiBsj4qGIeFjS1zTVnWeZpK0rb99K0nVd0ptExNERMS8i5m2yySaDXxkAAABggoxyVB9LOkbSooj4bCV980q2l0m6OD8+VdL+tte0va2kuZJ+L+k8SXNtb2t7DaUbgE8dxToAAAAAk2qUo/o8W9LrJF1k+4Kc9gFJr7a9o1J3nSWS3ixJEXGJ7ROVbtp9UNKhEfGQJNl+u6SfSZol6diIuGSE6wEAAABMnFGO6vNrte+ff1qX93xM0sfapJ/W7X0AAAAAmjFzLwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAAowssDf9ta2z7K9yPYltg/L6RvaPt32Ffn/Bjndto+0vdj2hbZ3qizroJz/CtsHjWodAAAAgEk1yhb/ByW9JyK2l7SrpENt7yDpcElnRMRcSWfk55K0t6S5+e8QSUdJ6URB0ock7SJpZ0kfapwsAAAAAGhvZIF/RFwfEX/Ij++UtEjSlpL2lXRcznacpP3y430lfTOScyStb3tzSS+SdHpE3BIRt0o6XdJeo1oPAAAAYBKNpY+/7TmSni7pXEmbRcT1Ujo5kLRpzralpKWVty3LaZ3SAQAAAHQw8sDf9jqSTpL0roi4o1vWNmnRJb31cw6xvdD2wuXLl0+vsAAAAMAqYqSBv+3VlYL+70TEyTn5xtyFR/n/TTl9maStK2/fStJ1XdKbRMTRETEvIuZtsskmg10RAAAAYMKMclQfSzpG0qKI+GzlpVMlNUbmOUjSKZX0A/PoPrtKuj13BfqZpD1tb5Bv6t0zpwEAAADoYPYIP+vZkl4n6SLbF+S0D0j6uKQTbb9R0jWSXplfO03SPpIWS/qrpNdLUkTcYvujks7L+T4SEbeMZhUAAACAyTSywD8ifq32/fMlaY82+UPSoR2WdaykYwdXOgAAAGDVxsy9AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApQO/C3vZvt2W3SZ9vebbDFAgAAADBI/bT4nyVpwzbp6+XXAAAAAMxQ/QT+lhRt0jeSdPdgigMAAABgGFboutPK9qn5YUj6tu37Ki/PkvRkSb8dQtkAAAAADEjPwF/SX/J/S7pV0j2V1+6X9GtJXxtwuQAAAAAMUM/APyJeL0m2l0j6dETQrQcAAACYMHVa/CVJEfHhYRYEAAAAwPDUDvxtbyjpY5L2kLSpWm4MjohHDbZoAAAAAAalduAv6RhJT5d0tKTr1H6EHwAAAAAzUD+B/x6SXhgR5w6rMAAAAACGo59x/G+SdNewCgIAAABgePoJ/P9F0kdsrzOswgAAAAAYjn66+nxQ0hxJN9m+WtID1Rcj4qkDLBcAAACAAeon8P/+0EoBAAAAYKgYxx8AAAAoQD99/AEAAABMqH4m8LpTXcbuZwIvAAAAYObqp4//21uer640odc/KM3oCwAAAGCG6qeP/3Ht0m3/QWlyry8MqlAAAAAABmsQffzPkvTSXplsH2v7JtsXV9KOsH2t7Qvy3z6V195ve7Hty2y/qJK+V05bbPvwAZQfAAAAWOUNIvDfX9LNNfItkLRXm/TPRcSO+e80SbK9Q17uk/J7vmx7lu1Zkr4kaW9JO0h6dc4LAAAAoIt+bu69SM0391rSZpI2lPTWXu+PiF/anlPz4/aVdEJE3CfpKtuLJe2cX1scEVfmMp2Q815ac7kAAABAkVZmAq+HJS2XdHZE/HklyvB22wdKWijpPRFxq6QtJZ1TybMsp0nS0pb0Xdot1PYhkg6RpG222WYligcAAABMvnFP4HWUpI8qXUn4qKTPSHqD0tWEFYqg9l2T2g4xGhFHSzpakubNm9dxGFIAAACgBP20+EuSbO+u1L8+JF0SEWdP98Mj4sbKcr8m6Uf56TJJW1eybiXpuvy4UzoAAACADvrp47+lpB9Ieoamgu0tbC+U9LKI6DsAt715RFyfn75MUmPEn1MlHW/7s5K2kDRX0u+VrgTMtb2tpGuVbgA+oN/PBQAAAErTT4v/kZIekvT4iLhKkmw/VtK382uv6PZm29+VNF/SxraXSfqQpPm2d1S6erBE0pslKSIusX2i0k27D0o6NCIeyst5u6SfSZol6diIuKSPdQAAAACK1E/g/0JJ8xtBvyRFxJW23ynpjF5vjohXt0k+pkv+j6nNjMB5yM/TapUYAAAAgKTBjOP/8ACWAQAAAGCI+gn8z5B0pO2/3VxrextJn1eNFn8AAAAA49NP4P9OSWtLutL21baXSPrfnPbOIZQNAAAAwID0M47/Ukk72X6hpO2URti5NCJ+PqzCAQAAABiMni3+tve2vcT2epIUEadHxBci4khJ5+XX9hx6SQEAAABMW52uPm+X9KmIuL31hZz2CUmHDbpgAAAAAAanTuD/VEnduvOcKelpgykOAAAAgGGoE/hvou5DdoakjQZTHAAAAADDUCfwX6bU6t/JUyVdO5jiAAAAABiGOoH/jyV91PZarS/YXlvSR3IeAAAAADNUneE8PybpFZKusP0FSX/O6dsr3fhrSf9vOMUDAAAAMAg9A/+IuMn2syQdpRTgu/GSpJ9JeltE3Di8IgIAAABYWbUm8IqIqyXtY3sDSY9XCv6viIhbh1k4AAAAAINRe+ZeScqB/nlDKgsAAACAIalzcy8AAACACUfgDwAAABSAwB8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAQj8AQAAgAIQ+AMAAAAFIPAHAAAACkDgDwAAABSAwB8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAQj8AQAAgAIQ+AMAAAAFIPAHAAAACkDgDwAAABSAwB8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAWaPuwBodvy51/SV/4BdthlSSQAAALAqocUfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAEI/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKMDIAn/bx9q+yfbFlbQNbZ9u+4r8f4OcbttH2l5s+0LbO1Xec1DOf4Xtg0ZVfgAAAGCSjbLFf4GkvVrSDpd0RkTMlXRGfi5Je0uam/8OkXSUlE4UJH1I0i6Sdpb0ocbJAgAAAIDORhb4R8QvJd3SkryvpOPy4+Mk7VdJ/2Yk50ha3/bmkl4k6fSIuCUibpV0ulY8mQAAAADQYtx9/DeLiOslKf/fNKdvKWlpJd+ynNYpHQAAAEAX4w78O3GbtOiSvuIC7ENsL7S9cPny5QMtHAAAADBpxh3435i78Cj/vymnL5O0dSXfVpKu65K+gog4OiLmRcS8TTbZZOAFBwAAACbJuAP/UyU1RuY5SNIplfQD8+g+u0q6PXcF+pmkPW1vkG/q3TOnAQAAAOhi9qg+yPZ3Jc2XtLHtZUqj83xc0om23yjpGkmvzNlPk7SPpMWS/irp9ZIUEbfY/qik83K+j0RE6w3DAAAAAFqMLPCPiFd3eGmPNnlD0qEdlnOspGMHWDQAAABglTfurj4AAAAARoDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACjA7HEXACvn+HOv6Sv/AbtsM6SSAAAAYCajxR8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAWZE4G97ie2LbF9ge2FO29D26bavyP83yOm2faTtxbYvtL3TeEsPAAAAzHwzIvDPnh8RO0bEvPz8cElnRMRcSWfk55K0t6S5+e8QSUeNvKQAAADAhJlJgX+rfSUdlx8fJ2m/Svo3IzlH0vq2Nx9HAQEAAIBJMVMC/5D0P7bPt31ITtssIq6XpPx/05y+paSllfcuy2lNbB9ie6HthcuXLx9i0QEAAICZb6ZM4PXsiLjO9qaSTrf95y553SYtVkiIOFrS0ZI0b968FV4HAAAASjIjWvwj4rr8/yZJP5C0s6QbG1148v+bcvZlkrauvH0rSdeNrrQAAADA5Bl74G/7kbbXbTyWtKekiyWdKumgnO0gSafkx6dKOjCP7rOrpNsbXYIAAAAAtDcTuvpsJukHtqVUnuMj4qe2z5N0ou03SrpG0itz/tMk7SNpsaS/Snr96IsMAAAATJaxB/4RcaWkp7VJ/4ukPdqkh6RDR1A0AAAAYJUx9q4+AAAAAIaPwB8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAQj8AQAAgAIQ+AMAAAAFIPAHAAAACkDgDwAAABSAwB8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAQj8AQAAgAIQ+AMAAAAFIPAHAAAACkDgDwAAABSAwB8AAAAoAIE/AAAAUAACfwAAAKAABP4AAABAAQj8AQAAgAIQ+AMAAAAFIPAHAAAACjB73AXAaB1/7jV9v+eAXbYZQkkAAAAwSrT4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKQOAPAAAAFIDAHwAAACgAgT8AAABQAAJ/AAAAoAAE/gAAAEABCPwBAACAAhD4AwAAAAWYPe4CYOY7/txr+sp/wC7bDKkkAAAAmC5a/AEAAIACEPgDAAAABSDwBwAAAApA4A8AAAAUgMAfAAAAKACBPwAAAFAAAn8AAACgAAT+AAAAQAGYwAsDx4RfAAAAMw8t/gAAAEABCPwBAACAAhD4AwAAAAUg8AcAAAAKwM29GDtuBgYAABg+WvwBAACAAhD4AwAAAAUg8AcAAAAKQB9/TBzuCQAAAOgfgT9WeZwoAAAATHBXH9t72b7M9mLbh4+7PAAAAMBMNpEt/rZnSfqSpBdKWibpPNunRsSl4y0ZVgX9XiGYDq4qAACAUZvIwF/SzpIWR8SVkmT7BEn7SiLwx0QYdvcjujcBAIBWkxr4bylpaeX5Mkm7jKkswNAN+yrEKK5yDNtMPDmaaSd4/eKEEABWLZMa+LtNWjRlsA+RdEh+epfty4ZeqhVtLOnmMXwuZg72gRF5zcxefq39YNjr0K+ZVp5VAPUBJPaDEjxm3AXoZFID/2WStq4830rSddUMEXG0pKNHWahWthdGxLxxlgHjxT4Aif0ACfsBJPYDjNekjupznqS5tre1vYak/SWdOuYyAQAAADPWRLb4R8SDtt8u6WeSZkk6NiIuGXOxAAAAgBlrIgN/SYqI0ySdNu5y9DDWrkaYEdgHILEfIGE/gMR+gDFyRPTOBQAAAGCiTWoffwAAAAB9IPAfAtt72b7M9mLbh4+7PBge21vbPsv2ItuX2D4sp29o+3TbV+T/G+R02z4y7xsX2t5pvGuAQbE9y/Yfbf8oP9/W9rl5H/heHohAttfMzxfn1+eMs9wYHNvr2/6+7T/nOuGZ1AXlsf3u/Htwse3v2n4E9QFmCgL/AbM9S9KXJO0taQdJr7a9w3hLhSF6UNJ7ImJ7SbtKOjR/34dLOiMi5ko6Iz+X0n4xN/8dIumo0RcZQ3KYpEWV55+Q9Lm8D9wq6Y05/Y2Sbo2Ix0v6XM6HVcPnJf00IraT9DSl/YG6oCC2t5T0TknzIuLJSgOQ7C/qA8wQBP6Dt7OkxRFxZUTcL+kESfuOuUwYkoi4PiL+kB/fqfRDv6XSd35cznacpP3y430lfTOScyStb3vzERcbA2Z7K0kvlvT1/NySdpf0/ZyldR9o7Bvfl7RHzo8JZvtRknaTdIwkRcT9EXGbqAtKNFvSWrZnS1pb0vWiPsAMQeA/eFtKWlp5viynYRWXL9E+XdK5kjaLiOuldHIgadOcjf1j1fSfkt4n6eH8fCNJt0XEg/l59Xv+2z6QX78958dke6yk5ZK+kbt8fd32I0VdUJSIuFbSpyVdoxTw3y7pfFEfYIYg8B+8dmfqDJ20irO9jqSTJL0rIu7olrVNGvvHBLP9Ekk3RcT51eQ2WaPGa5hcsyXtJOmoiHi6pLs11a2nHfaDVVC+h2NfSdtK2kLSI5W6dbWiPsBYEPgP3jJJW1eebyXpujGVBSNge3WloP87EXFyTr6xcdk+/78pp7N/rHqeLenvbS9R6tq3u9IVgPXzpX6p+Xv+2z6QX19P0i2jLDCGYpmkZRFxbn7+faUTAeqCsrxA0lURsTwiHpB0sqRnifoAMwSB/+CdJ2luvoN/DaWbek4dc5kwJLkv5jGSFkXEZysvnSrpoPz4IEmnVNIPzCN67Crp9kY3AEymiHh/RGwVEXOUjvczI+I1ks6S9IqcrXUfaOwbr8j5aeGbcBFxg6Sltp+Yk/aQdKmoC0pzjaRdba+dfx8a+wH1AWYEJvAaAtv7KLX4zZJ0bER8bMxFwpDYfo6kX0m6SFP9uz+g1M//RP3/9u4/yKqyjuP4+6NCYGaNWWImmjRBAw0iZjX+QshEoXEY+gGpySZNQ07/KOOMxcSSMpOGf9SUQ/CHCJJogS2iZqJEpoYwwBgDQs3OogyTElrx25RvfzzPLqcz+3vv7nbnfl4zZ7jnnnO+z/fes+x+73Oe51wYSvpD8NWIeCv/Ifg5MBE4DNRFxKY+T9x6haRxwOyImCzpAtIVgDOALcCNEXFM0iBgGWk+yFvAtIho7K+crXIkXUia4D0QaATqSB1s/l1QQyTNA75OuuvbFmAmaSy/fx9Yv3Phb2ZmZmZWAzzUx8zMzMysBrjwNzMzMzOrAS78zczMzMxqgAt/MzMzM7Ma4MLfsRM6vAAABqBJREFUzMzMzKwGuPA3MzPrZZLOlxSSLu7vXMysdrnwN7OqJmmMpPckvdDfufSV/AWBD0naI+mYpL2SnpA0psLt1EvaVsmYvUnSEklrnIeZWetc+JtZtfs2cD8wStKn+6JBSQP6op122n4G+AjwNeBTpG/8fJn05UBmZmatcuFvZlVL0mDgG8Bi4DfALaXtL0m6r/Tc6ZKOSJqS1wdKuif3nh+StFHSNYX9x+UhGtdJelnSO8A1koZJapD093zcZkmTS22dJWl1bm+3pDpJ2yTVF/b5oKRFkt6UdEDS+g6Gg4wEhgG3RsSLEbE7/zsvIp7tbFxJMyQdlDQh53RI0jpJn2jeDswFRubXH/m5Hscu7DdJ0ob8/uyX9Hj+JtMOz0t3VDDvOyW9kfddKmmupKa8rR64GZhUeN/GFQ4/T9Izkg5L2i7p6p68JjOzrnDhb2bV7CvA7oh4hfS1998s9cY/BEyTVPxdNxU4AjyR1x8AriR9gPgM8CDwuKTRpbbuAeYAI4ANwGnAU8DVwGhgJbBK0ojCMQ8C5wHjgeuBG/M6AJKU8zgHmAyMAf4IPCfp7DZe8z7gODBV0imt7dCFuO8D7gS+BXwB+BCwMG97BLgP2AmcnZdHKhQbSROBBtLVi7HAVcB6Tvxd6ux56ZQK5j2N9IHoB8BFwA7gtsLxC4BHgbWceN9eLGyfD/yM9DOzEVgh6bTuvCYzsy6LCC9evHipyoVUKM7OjwU0AVML2z8MvANMKDy3FvhlfjyMVEQPLcX9LXB/fjwOiGLcdvL5MzAnPx6ej/t8Yfu5wHtAfV4fDxwEBpfibAXuaKedW4FD+dj1wF3AyML2DuMCM3J+wwvbb8jv10l5vR7YVopRqdgvACvaeH0dnpc2jlsCrGljW6XyfglYWIrxe6CpvTyA83Ps7xSeOyc/d1l//1/y4sVLbSzu8TezqiTpk8ClwK8AIiKA5cDM5n0iYj/wNKl4I/fsXkW6EgCpx1bA9jxs46Ckg8AkUvFZtKnU/vsl3ZuHa7ydj7sYGJp3GUEqXluOi4jXgb2FMGOBU4F9pfZHtdJ+i4j4BTCE1Bv+J9LVhK2Sbupi3GMRsbOwvhcYQOrlbkulYo8BnqV1XTkvnVWpvEeQ5lMUbehCHq+UYgN8tAvHm5l1W6uXic3MqsBM4GTgtTSKA0jFIpLOzUU2pCJ/kaTvAtOB10nFMqRhJQF8FvhPKf6R0vqh0voCYCIwG/grcBhYCgws5tKBk4A3gMtb2fbv9g6MiAPAamC1pDmkDzh3kYY8dTbuu+Wwhbx6mnN3Yhfb6Ox56axK5h10X8vriYjIP7vuhDOzPuHC38yqTh7bfjNpLHb5tonLgDrgR3m9AVhEGtd9A7A8Xx0A2EIq0IdExLoupnEZsDQiVuacBpF6jnfl7TtIBd1Yco+wpI8DHyvE2AycBRyPiMYutt8iF5CvknrKKxaXNMTl5NJzlYq9BZhAmpjd2rbunpe2VCrvV4FLSHMQml1S2qe1983MrN+58DezajQJOBNYnIfztJC0Apgl6e6IOB4RRyWtIk3MHU2aYAtAROyStBxYIul2UnF4Bmlcf2NErGonh13AFEkNpF7cucCgQuydkp4GFkqaBRwFfkK6MtD8wWMtaax7g6Q7SEXlENKVhLUR8Xy5UUkXAvNIH3C2k4rMK0mTUR/ubtw2NJHuQnMR8BpwoIKx55Mm6/6NNFxLwJdI8y96cl5Oz+9R0T8rmPdPgQckbQSeB6YAnwPeLuzTBFwraTiwH/hXJ2ObmfUqX140s2p0C7CuXPRnvybdOeeLheeWkYr+zRGxo7R/Han39l5SMbgGuALY3UEOtwFvkoq/p0gTe8vF4wxgD/AH0rCc5fmYo9AyL+E64DlSz/dO0h1hhvO/cwGK9gCNwA9zm1uB20lDj77Xg7itWQk8SRqLvw+YXqnYEfEkqWi+ltTDv540/+J43qW75+XyHK+4LKhg3itIQ6p+nGOPIt3152hht8WkKz6bSO/bpZ2Nb2bWm3TiireZmfUmSWeSiszpzUOErPpJegw4JSK+3N+5mJm1x0N9zMx6iaTxwAeAv5Du3DIf+Afwu/7My7pP0qnALNI5fJf0vRDX53/NzP6vufA3M+s9A4C7gQtIY/s3AFdERPkOQVY9gjQ86fvAYNIdnW6KiMf6NSszs07wUB8zMzMzsxrgyb1mZmZmZjXAhb+ZmZmZWQ1w4W9mZmZmVgNc+JuZmZmZ1QAX/mZmZmZmNcCFv5mZmZlZDfgvjjz+sjFHLN8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "sns.distplot(df.avg_sentence_length, kde=False)\n",
    "plt.xlabel('Average Sentence Length', size=14)\n",
    "plt.ylabel('Count', size=14);\n",
    "plt.title('Distribution of Average Sentence Length', fontsize=36);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.676465218185136"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"avg_sentence_length\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - Log Reg, standard stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standard stop words = \"english\"\n",
    "#incorporating a pipeline for tranforming\n",
    "\n",
    "cvec = CountVectorizer(analyzer = \"word\",                        \n",
    "                         tokenizer = None, \n",
    "                         preprocessor = None,\n",
    "                         stop_words = \"english\", \n",
    "                         max_features = 10000)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('lr', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9581202824446068\n",
      "test score: 0.7846715328467153\n"
     ]
    }
   ],
   "source": [
    "# baseline Logistic model\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"There are {} features in the model.\".format(len(cvec.get_feature_names())))\n",
    "print('train score:', pipe.score(X_train, y_train))\n",
    "print('test score:', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Intercept: [0.00022423]\n",
      "Logistic Regression Coefficient: [[ 0.18769812 -0.00772207 -0.00028316 ...  0.20491638 -0.1613094\n",
      "  -0.16065708]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Intercept: {lr.intercept_}')\n",
    "print(f'Logistic Regression Coefficient: {lr.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.688698\n",
       "1    0.311302\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the accuracy of our baseline model?\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline accuracy for this model is nan%.\n"
     ]
    }
   ],
   "source": [
    "print(\"The baseline accuracy for this model is {:.2f}%.\".format(\n",
    "    cross_val_score(lr, X_train, y_train).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FEATURE IMPORTANCE** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elon</th>\n",
       "      <td>2.105573</td>\n",
       "      <td>2.105573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mar</th>\n",
       "      <td>1.936468</td>\n",
       "      <td>1.936468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>-1.484852</td>\n",
       "      <td>1.484852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self</th>\n",
       "      <td>-1.454748</td>\n",
       "      <td>1.454748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meme</th>\n",
       "      <td>1.453297</td>\n",
       "      <td>1.453297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>1.388775</td>\n",
       "      <td>1.388775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocket</th>\n",
       "      <td>1.331333</td>\n",
       "      <td>1.331333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>-1.330616</td>\n",
       "      <td>1.330616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>1.330210</td>\n",
       "      <td>1.330210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>literally</th>\n",
       "      <td>-1.325280</td>\n",
       "      <td>1.325280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>-1.324366</td>\n",
       "      <td>1.324366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>password</th>\n",
       "      <td>1.298299</td>\n",
       "      <td>1.298299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norway</th>\n",
       "      <td>1.294580</td>\n",
       "      <td>1.294580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grime</th>\n",
       "      <td>1.287395</td>\n",
       "      <td>1.287395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bot</th>\n",
       "      <td>1.279083</td>\n",
       "      <td>1.279083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greatest</th>\n",
       "      <td>1.256050</td>\n",
       "      <td>1.256050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gif</th>\n",
       "      <td>1.246891</td>\n",
       "      <td>1.246891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralink</th>\n",
       "      <td>1.242132</td>\n",
       "      <td>1.242132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exist</th>\n",
       "      <td>-1.236697</td>\n",
       "      <td>1.236697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>-1.225171</td>\n",
       "      <td>1.225171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>living</th>\n",
       "      <td>-1.218789</td>\n",
       "      <td>1.218789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>1.209546</td>\n",
       "      <td>1.209546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydrogen</th>\n",
       "      <td>-1.166658</td>\n",
       "      <td>1.166658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>1.159940</td>\n",
       "      <td>1.159940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assuming</th>\n",
       "      <td>-1.157074</td>\n",
       "      <td>1.157074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ash</th>\n",
       "      <td>1.154230</td>\n",
       "      <td>1.154230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas</th>\n",
       "      <td>-1.140874</td>\n",
       "      <td>1.140874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>-1.130238</td>\n",
       "      <td>1.130238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>1.120600</td>\n",
       "      <td>1.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>-1.114378</td>\n",
       "      <td>1.114378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef_  abs_coef\n",
       "elon        2.105573  2.105573\n",
       "mar         1.936468  1.936468\n",
       "article    -1.484852  1.484852\n",
       "self       -1.454748  1.454748\n",
       "meme        1.453297  1.453297\n",
       "stock       1.388775  1.388775\n",
       "rocket      1.331333  1.331333\n",
       "power      -1.330616  1.330616\n",
       "hour        1.330210  1.330210\n",
       "literally  -1.325280  1.325280\n",
       "water      -1.324366  1.324366\n",
       "password    1.298299  1.298299\n",
       "norway      1.294580  1.294580\n",
       "grime       1.287395  1.287395\n",
       "bot         1.279083  1.279083\n",
       "greatest    1.256050  1.256050\n",
       "gif         1.246891  1.246891\n",
       "neuralink   1.242132  1.242132\n",
       "exist      -1.236697  1.236697\n",
       "land       -1.225171  1.225171\n",
       "living     -1.218789  1.218789\n",
       "school      1.209546  1.209546\n",
       "hydrogen   -1.166658  1.166658\n",
       "spend       1.159940  1.159940\n",
       "assuming   -1.157074  1.157074\n",
       "ash         1.154230  1.154230\n",
       "gas        -1.140874  1.140874\n",
       "absolutely -1.130238  1.130238\n",
       "bmw         1.120600  1.120600\n",
       "support    -1.114378  1.114378"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_feat00 = pd.DataFrame(data=lr.coef_.T, index=cvec.get_feature_names())\n",
    "lr_feat00.columns = ['coef_']\n",
    "lr_feat00['abs_coef'] = np.abs(lr_feat00['coef_'])\n",
    "lr_feat00.sort_values(by='abs_coef', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Log Reg, custom stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using additional stop words\n",
    "\n",
    "cvec2 = CountVectorizer(analyzer = \"word\",                        \n",
    "                         tokenizer = None, \n",
    "                         preprocessor = None,\n",
    "                         stop_words = stop_words, \n",
    "                         max_features = 10000)\n",
    "lr2 = LogisticRegression()\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('cvec2', cvec2),\n",
    "    ('lr2', lr2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9556854151448746\n",
      "test score: 0.7839416058394161\n"
     ]
    }
   ],
   "source": [
    "# baseline Logistic model # 2\n",
    "\n",
    "pipe2.fit(X_train, y_train)\n",
    "print(\"There are {} features in the model.\".format(len(cvec2.get_feature_names())))\n",
    "print('train score:', pipe2.score(X_train, y_train))\n",
    "print('test score:', pipe2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elite</th>\n",
       "      <td>2.070460</td>\n",
       "      <td>2.070460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mansion</th>\n",
       "      <td>1.912937</td>\n",
       "      <td>1.912937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>megastructures</th>\n",
       "      <td>1.483922</td>\n",
       "      <td>1.483922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>-1.458497</td>\n",
       "      <td>1.458497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stockfish</th>\n",
       "      <td>1.429008</td>\n",
       "      <td>1.429008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfdrivingcars</th>\n",
       "      <td>-1.423398</td>\n",
       "      <td>1.423398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powerdrift</th>\n",
       "      <td>-1.347417</td>\n",
       "      <td>1.347417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hormone</th>\n",
       "      <td>1.328163</td>\n",
       "      <td>1.328163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocketjesus</th>\n",
       "      <td>1.325239</td>\n",
       "      <td>1.325239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nope</th>\n",
       "      <td>1.313137</td>\n",
       "      <td>1.313137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>-1.307126</td>\n",
       "      <td>1.307126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listened</th>\n",
       "      <td>-1.293630</td>\n",
       "      <td>1.293630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nerd</th>\n",
       "      <td>1.288694</td>\n",
       "      <td>1.288694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>germany</th>\n",
       "      <td>1.287760</td>\n",
       "      <td>1.287760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bot</th>\n",
       "      <td>1.265281</td>\n",
       "      <td>1.265281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lady</th>\n",
       "      <td>-1.252152</td>\n",
       "      <td>1.252152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pas</th>\n",
       "      <td>1.251566</td>\n",
       "      <td>1.251566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grass</th>\n",
       "      <td>1.240221</td>\n",
       "      <td>1.240221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>1.235978</td>\n",
       "      <td>1.235978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>littering</th>\n",
       "      <td>-1.221977</td>\n",
       "      <td>1.221977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schooling</th>\n",
       "      <td>1.211843</td>\n",
       "      <td>1.211843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gangsta</th>\n",
       "      <td>-1.186164</td>\n",
       "      <td>1.186164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <td>-1.182221</td>\n",
       "      <td>1.182221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband</th>\n",
       "      <td>-1.177386</td>\n",
       "      <td>1.177386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ash</th>\n",
       "      <td>1.176897</td>\n",
       "      <td>1.176897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assuming</th>\n",
       "      <td>-1.170345</td>\n",
       "      <td>1.170345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supported</th>\n",
       "      <td>-1.168555</td>\n",
       "      <td>1.168555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>1.168385</td>\n",
       "      <td>1.168385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared</th>\n",
       "      <td>1.141225</td>\n",
       "      <td>1.141225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initiative</th>\n",
       "      <td>1.130856</td>\n",
       "      <td>1.130856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coef_  abs_coef\n",
       "elite            2.070460  2.070460\n",
       "mansion          1.912937  1.912937\n",
       "megastructures   1.483922  1.483922\n",
       "article         -1.458497  1.458497\n",
       "stockfish        1.429008  1.429008\n",
       "selfdrivingcars -1.423398  1.423398\n",
       "powerdrift      -1.347417  1.347417\n",
       "hormone          1.328163  1.328163\n",
       "rocketjesus      1.325239  1.325239\n",
       "nope             1.313137  1.313137\n",
       "water           -1.307126  1.307126\n",
       "listened        -1.293630  1.293630\n",
       "nerd             1.288694  1.288694\n",
       "germany          1.287760  1.287760\n",
       "bot              1.265281  1.265281\n",
       "lady            -1.252152  1.252152\n",
       "pas              1.251566  1.251566\n",
       "grass            1.240221  1.240221\n",
       "green            1.235978  1.235978\n",
       "littering       -1.221977  1.221977\n",
       "schooling        1.211843  1.211843\n",
       "gangsta         -1.186164  1.186164\n",
       "exercise        -1.182221  1.182221\n",
       "husband         -1.177386  1.177386\n",
       "ash              1.176897  1.176897\n",
       "assuming        -1.170345  1.170345\n",
       "supported       -1.168555  1.168555\n",
       "bmw              1.168385  1.168385\n",
       "shared           1.141225  1.141225\n",
       "initiative       1.130856  1.130856"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_feat02 = pd.DataFrame(data=lr2.coef_.T, index=cvec.get_feature_names())\n",
    "lr_feat02.columns = ['coef_']\n",
    "lr_feat02['abs_coef'] = np.abs(lr_feat02['coef_'])\n",
    "lr_feat02.sort_values(by='abs_coef', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.688698\n",
       "1    0.311302\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the accuracy of our baseline model?\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Logistic Regression Intercept: {lr2.intercept_}')\n",
    "#print(f'Logistic Regression Coefficient: {lr2.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6672"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate against the baseline.\n",
    "round(y_test.value_counts(normalize=True)[0], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - Log Reg, custom stopwords, n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec3 = CountVectorizer(analyzer = \"word\", \n",
    "                       tokenizer = None, \n",
    "                       preprocessor = None,\n",
    "                       stop_words = stop_words, \n",
    "                       max_features = 10000, \n",
    "                       ngram_range = (1, 3)\n",
    "                      )\n",
    "\n",
    "lr3 = LogisticRegression()\n",
    "\n",
    "pipe3 = Pipeline([\n",
    "    ('cvec3', cvec3),\n",
    "    ('lr3', lr3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9503287070854638\n",
      "test score: 0.789051094890511\n"
     ]
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)\n",
    "print(\"There are {} features in the model.\".format(len(cvec3.get_feature_names())))\n",
    "print('train score:', pipe3.score(X_train, y_train))\n",
    "print('test score:', pipe3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>foot ground</th>\n",
       "      <td>2.105573</td>\n",
       "      <td>2.105573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mainly</th>\n",
       "      <td>1.936468</td>\n",
       "      <td>1.936468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <td>-1.484852</td>\n",
       "      <td>1.484852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running</th>\n",
       "      <td>-1.454748</td>\n",
       "      <td>1.454748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>1.453297</td>\n",
       "      <td>1.453297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>1.388775</td>\n",
       "      <td>1.388775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repeal</th>\n",
       "      <td>1.331333</td>\n",
       "      <td>1.331333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pissing</th>\n",
       "      <td>-1.330616</td>\n",
       "      <td>1.330616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydrogen</th>\n",
       "      <td>1.330210</td>\n",
       "      <td>1.330210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let happen</th>\n",
       "      <td>-1.325280</td>\n",
       "      <td>1.325280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vessel</th>\n",
       "      <td>-1.324366</td>\n",
       "      <td>1.324366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>1.298299</td>\n",
       "      <td>1.298299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>1.294580</td>\n",
       "      <td>1.294580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear</th>\n",
       "      <td>1.287395</td>\n",
       "      <td>1.287395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communist</th>\n",
       "      <td>1.279083</td>\n",
       "      <td>1.279083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heal</th>\n",
       "      <td>1.256050</td>\n",
       "      <td>1.256050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard</th>\n",
       "      <td>1.246891</td>\n",
       "      <td>1.246891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>1.242132</td>\n",
       "      <td>1.242132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation 2020</th>\n",
       "      <td>-1.236697</td>\n",
       "      <td>1.236697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just bought</th>\n",
       "      <td>-1.225171</td>\n",
       "      <td>1.225171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libertarian</th>\n",
       "      <td>-1.218789</td>\n",
       "      <td>1.218789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right track</th>\n",
       "      <td>1.209546</td>\n",
       "      <td>1.209546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idgaf</th>\n",
       "      <td>-1.166658</td>\n",
       "      <td>1.166658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smaller</th>\n",
       "      <td>1.159940</td>\n",
       "      <td>1.159940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>california</th>\n",
       "      <td>-1.157074</td>\n",
       "      <td>1.157074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>busy</th>\n",
       "      <td>1.154230</td>\n",
       "      <td>1.154230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand big</th>\n",
       "      <td>-1.140874</td>\n",
       "      <td>1.140874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authoritarian</th>\n",
       "      <td>-1.130238</td>\n",
       "      <td>1.130238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come day</th>\n",
       "      <td>1.120600</td>\n",
       "      <td>1.120600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop burning</th>\n",
       "      <td>-1.114378</td>\n",
       "      <td>1.114378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losing</th>\n",
       "      <td>-1.110670</td>\n",
       "      <td>1.110670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1.106519</td>\n",
       "      <td>1.106519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evening</th>\n",
       "      <td>1.103018</td>\n",
       "      <td>1.103018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>held responsible</th>\n",
       "      <td>1.096187</td>\n",
       "      <td>1.096187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>1.091095</td>\n",
       "      <td>1.091095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obtain</th>\n",
       "      <td>-1.082540</td>\n",
       "      <td>1.082540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refer</th>\n",
       "      <td>-1.079549</td>\n",
       "      <td>1.079549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrible</th>\n",
       "      <td>1.078189</td>\n",
       "      <td>1.078189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really comparing</th>\n",
       "      <td>-1.070310</td>\n",
       "      <td>1.070310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>-1.064663</td>\n",
       "      <td>1.064663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycle count</th>\n",
       "      <td>-1.063419</td>\n",
       "      <td>1.063419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey</th>\n",
       "      <td>1.059330</td>\n",
       "      <td>1.059330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just people</th>\n",
       "      <td>-1.038437</td>\n",
       "      <td>1.038437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wearing</th>\n",
       "      <td>-1.024922</td>\n",
       "      <td>1.024922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handing</th>\n",
       "      <td>1.024478</td>\n",
       "      <td>1.024478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rethink</th>\n",
       "      <td>1.012624</td>\n",
       "      <td>1.012624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected</th>\n",
       "      <td>-1.012282</td>\n",
       "      <td>1.012282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinderbox</th>\n",
       "      <td>1.005299</td>\n",
       "      <td>1.005299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photothermal</th>\n",
       "      <td>-1.000757</td>\n",
       "      <td>1.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat belly</th>\n",
       "      <td>-0.994123</td>\n",
       "      <td>0.994123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     coef_  abs_coef\n",
       "foot ground       2.105573  2.105573\n",
       "mainly            1.936468  1.936468\n",
       "bus              -1.484852  1.484852\n",
       "running          -1.454748  1.454748\n",
       "med               1.453297  1.453297\n",
       "spam              1.388775  1.388775\n",
       "repeal            1.331333  1.331333\n",
       "pissing          -1.330616  1.330616\n",
       "hydrogen          1.330210  1.330210\n",
       "let happen       -1.325280  1.325280\n",
       "vessel           -1.324366  1.324366\n",
       "pain              1.298299  1.298299\n",
       "normal            1.294580  1.294580\n",
       "hear              1.287395  1.287395\n",
       "communist         1.279083  1.279083\n",
       "heal              1.256050  1.256050\n",
       "hard              1.246891  1.246891\n",
       "new york          1.242132  1.242132\n",
       "generation 2020  -1.236697  1.236697\n",
       "just bought      -1.225171  1.225171\n",
       "libertarian      -1.218789  1.218789\n",
       "right track       1.209546  1.209546\n",
       "idgaf            -1.166658  1.166658\n",
       "smaller           1.159940  1.159940\n",
       "california       -1.157074  1.157074\n",
       "busy              1.154230  1.154230\n",
       "hand big         -1.140874  1.140874\n",
       "authoritarian    -1.130238  1.130238\n",
       "come day          1.120600  1.120600\n",
       "stop burning     -1.114378  1.114378\n",
       "losing           -1.110670  1.110670\n",
       "say               1.106519  1.106519\n",
       "evening           1.103018  1.103018\n",
       "held responsible  1.096187  1.096187\n",
       "indian            1.091095  1.091095\n",
       "obtain           -1.082540  1.082540\n",
       "refer            -1.079549  1.079549\n",
       "horrible          1.078189  1.078189\n",
       "really comparing -1.070310  1.070310\n",
       "concrete         -1.064663  1.064663\n",
       "cycle count      -1.063419  1.063419\n",
       "hey               1.059330  1.059330\n",
       "just people      -1.038437  1.038437\n",
       "wearing          -1.024922  1.024922\n",
       "handing           1.024478  1.024478\n",
       "rethink           1.012624  1.012624\n",
       "detected         -1.012282  1.012282\n",
       "tinderbox         1.005299  1.005299\n",
       "photothermal     -1.000757  1.000757\n",
       "fat belly        -0.994123  0.994123"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_feat03 = pd.DataFrame(data=lr.coef_.T, index=cvec3.get_feature_names())\n",
    "lr_feat03.columns = ['coef_']\n",
    "lr_feat03['abs_coef'] = np.abs(lr_feat03['coef_'])\n",
    "lr_feat03.sort_values(by='abs_coef', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elon</th>\n",
       "      <td>2.368718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mar</th>\n",
       "      <td>2.030582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meme</th>\n",
       "      <td>1.472988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>1.448897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bot</th>\n",
       "      <td>1.262168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gif</th>\n",
       "      <td>1.246472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralink</th>\n",
       "      <td>1.242925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>1.212570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musk</th>\n",
       "      <td>1.198856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norway</th>\n",
       "      <td>1.192203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grime</th>\n",
       "      <td>1.169565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>1.155197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocket</th>\n",
       "      <td>1.138923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ash</th>\n",
       "      <td>1.126105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innovator</th>\n",
       "      <td>1.099734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>1.072019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heard</th>\n",
       "      <td>1.048936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greatest</th>\n",
       "      <td>1.045180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen</th>\n",
       "      <td>1.036295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>password</th>\n",
       "      <td>1.030718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>1.019725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>1.012199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hell</th>\n",
       "      <td>1.010122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didnt</th>\n",
       "      <td>1.008738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shirt</th>\n",
       "      <td>0.990331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <td>0.975871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high school</th>\n",
       "      <td>0.966762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handwriting</th>\n",
       "      <td>0.963111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>letter</th>\n",
       "      <td>0.961190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>figured</th>\n",
       "      <td>0.959214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef_\n",
       "elon         2.368718\n",
       "mar          2.030582\n",
       "meme         1.472988\n",
       "stock        1.448897\n",
       "bot          1.262168\n",
       "gif          1.246472\n",
       "neuralink    1.242925\n",
       "hour         1.212570\n",
       "musk         1.198856\n",
       "norway       1.192203\n",
       "grime        1.169565\n",
       "bmw          1.155197\n",
       "rocket       1.138923\n",
       "ash          1.126105\n",
       "innovator    1.099734\n",
       "hair         1.072019\n",
       "heard        1.048936\n",
       "greatest     1.045180\n",
       "gen          1.036295\n",
       "password     1.030718\n",
       "school       1.019725\n",
       "spend        1.012199\n",
       "hell         1.010122\n",
       "didnt        1.008738\n",
       "shirt        0.990331\n",
       "split        0.975871\n",
       "high school  0.966762\n",
       "handwriting  0.963111\n",
       "letter       0.961190\n",
       "figured      0.959214"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_feat03 = pd.DataFrame(data=lr3.coef_.T, index=cvec3.get_feature_names())\n",
    "logreg_feat03.columns = ['coef_']\n",
    "logreg_feat03.sort_values(by='coef_', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 - Log Reg using tf-idf, custom stop words, n-grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.8463598733869004\n",
      "test score: 0.7700729927007299\n"
     ]
    }
   ],
   "source": [
    "tf = TfidfVectorizer(analyzer = \"word\", \n",
    "                     stop_words = stop_words, \n",
    "                     max_features = 10000, \n",
    "                     ngram_range = (1, 3))\n",
    "\n",
    "lr4 = LogisticRegression()\n",
    "\n",
    "pipe4 = Pipeline([\n",
    "    ('tf', tf),\n",
    "    ('lr4', lr4)\n",
    "])\n",
    "\n",
    "pipe4.fit(X_train, y_train)\n",
    "print(\"There are {} features in the model.\".format(len(tf.get_feature_names())))\n",
    "print('train score:', pipe4.score(X_train, y_train))\n",
    "print('test score:', pipe4.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Intercept: [-0.50562276]\n",
      "Logistic Regression Coefficient: [[-0.25640487 -0.11148296 -0.0242847  ... -0.06054537 -0.06054537\n",
      "   0.07144286]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Intercept: {lr4.intercept_}')\n",
    "print(f'Logistic Regression Coefficient: {lr4.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deaf</th>\n",
       "      <td>5.378897</td>\n",
       "      <td>5.378897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximize</th>\n",
       "      <td>3.158363</td>\n",
       "      <td>3.158363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmsi</th>\n",
       "      <td>2.558394</td>\n",
       "      <td>2.558394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promote</th>\n",
       "      <td>-2.405181</td>\n",
       "      <td>2.405181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superimpose</th>\n",
       "      <td>2.056270</td>\n",
       "      <td>2.056270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whore</th>\n",
       "      <td>-1.937604</td>\n",
       "      <td>1.937604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow</th>\n",
       "      <td>-1.913854</td>\n",
       "      <td>1.913854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cerpheus27</th>\n",
       "      <td>-1.911301</td>\n",
       "      <td>1.911301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delighted</th>\n",
       "      <td>-1.884095</td>\n",
       "      <td>1.884095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nature</th>\n",
       "      <td>1.775707</td>\n",
       "      <td>1.775707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morally</th>\n",
       "      <td>-1.750682</td>\n",
       "      <td>1.750682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-1.700714</td>\n",
       "      <td>1.700714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercantile</th>\n",
       "      <td>1.681061</td>\n",
       "      <td>1.681061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biofuels</th>\n",
       "      <td>-1.636286</td>\n",
       "      <td>1.636286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squeegee</th>\n",
       "      <td>-1.627070</td>\n",
       "      <td>1.627070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outgassing</th>\n",
       "      <td>-1.576345</td>\n",
       "      <td>1.576345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>-1.556054</td>\n",
       "      <td>1.556054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sticking</th>\n",
       "      <td>1.545644</td>\n",
       "      <td>1.545644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caused</th>\n",
       "      <td>-1.526932</td>\n",
       "      <td>1.526932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expressed</th>\n",
       "      <td>1.521964</td>\n",
       "      <td>1.521964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>-1.476681</td>\n",
       "      <td>1.476681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levere</th>\n",
       "      <td>-1.474745</td>\n",
       "      <td>1.474745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinderbox</th>\n",
       "      <td>1.450180</td>\n",
       "      <td>1.450180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machinery</th>\n",
       "      <td>1.448674</td>\n",
       "      <td>1.448674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eucalyptus</th>\n",
       "      <td>-1.441256</td>\n",
       "      <td>1.441256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgetting</th>\n",
       "      <td>1.432802</td>\n",
       "      <td>1.432802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uterus</th>\n",
       "      <td>1.408669</td>\n",
       "      <td>1.408669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heavily</th>\n",
       "      <td>1.407832</td>\n",
       "      <td>1.407832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>-1.360687</td>\n",
       "      <td>1.360687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortage</th>\n",
       "      <td>1.355582</td>\n",
       "      <td>1.355582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nickel</th>\n",
       "      <td>1.347784</td>\n",
       "      <td>1.347784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screenshots</th>\n",
       "      <td>1.329926</td>\n",
       "      <td>1.329926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>successful</th>\n",
       "      <td>-1.329157</td>\n",
       "      <td>1.329157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropogenic</th>\n",
       "      <td>1.292111</td>\n",
       "      <td>1.292111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assuming</th>\n",
       "      <td>-1.291692</td>\n",
       "      <td>1.291692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clumsy</th>\n",
       "      <td>-1.277905</td>\n",
       "      <td>1.277905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>-1.277333</td>\n",
       "      <td>1.277333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quiet</th>\n",
       "      <td>-1.275383</td>\n",
       "      <td>1.275383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stepped</th>\n",
       "      <td>1.258255</td>\n",
       "      <td>1.258255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batts</th>\n",
       "      <td>-1.256008</td>\n",
       "      <td>1.256008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>necessary</th>\n",
       "      <td>-1.246024</td>\n",
       "      <td>1.246024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>-1.244757</td>\n",
       "      <td>1.244757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lucky</th>\n",
       "      <td>1.244421</td>\n",
       "      <td>1.244421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>1.236381</td>\n",
       "      <td>1.236381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collide</th>\n",
       "      <td>-1.223941</td>\n",
       "      <td>1.223941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counterexample</th>\n",
       "      <td>-1.222887</td>\n",
       "      <td>1.222887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rioter</th>\n",
       "      <td>-1.220632</td>\n",
       "      <td>1.220632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defense</th>\n",
       "      <td>1.211632</td>\n",
       "      <td>1.211632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makeup</th>\n",
       "      <td>-1.209765</td>\n",
       "      <td>1.209765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awareness</th>\n",
       "      <td>-1.207143</td>\n",
       "      <td>1.207143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coef_  abs_coef\n",
       "deaf            5.378897  5.378897\n",
       "maximize        3.158363  3.158363\n",
       "mmsi            2.558394  2.558394\n",
       "promote        -2.405181  2.405181\n",
       "superimpose     2.056270  2.056270\n",
       "whore          -1.937604  1.937604\n",
       "yellow         -1.913854  1.913854\n",
       "cerpheus27     -1.911301  1.911301\n",
       "delighted      -1.884095  1.884095\n",
       "nature          1.775707  1.775707\n",
       "morally        -1.750682  1.750682\n",
       "796            -1.700714  1.700714\n",
       "mercantile      1.681061  1.681061\n",
       "biofuels       -1.636286  1.636286\n",
       "squeegee       -1.627070  1.627070\n",
       "outgassing     -1.576345  1.576345\n",
       "field          -1.556054  1.556054\n",
       "sticking        1.545644  1.545644\n",
       "caused         -1.526932  1.526932\n",
       "expressed       1.521964  1.521964\n",
       "sister         -1.476681  1.476681\n",
       "levere         -1.474745  1.474745\n",
       "tinderbox       1.450180  1.450180\n",
       "machinery       1.448674  1.448674\n",
       "eucalyptus     -1.441256  1.441256\n",
       "forgetting      1.432802  1.432802\n",
       "uterus          1.408669  1.408669\n",
       "heavily         1.407832  1.407832\n",
       "louis          -1.360687  1.360687\n",
       "shortage        1.355582  1.355582\n",
       "nickel          1.347784  1.347784\n",
       "screenshots     1.329926  1.329926\n",
       "successful     -1.329157  1.329157\n",
       "anthropogenic   1.292111  1.292111\n",
       "assuming       -1.291692  1.291692\n",
       "clumsy         -1.277905  1.277905\n",
       "hour           -1.277333  1.277333\n",
       "quiet          -1.275383  1.275383\n",
       "stepped         1.258255  1.258255\n",
       "batts          -1.256008  1.256008\n",
       "necessary      -1.246024  1.246024\n",
       "beta           -1.244757  1.244757\n",
       "lucky           1.244421  1.244421\n",
       "anger           1.236381  1.236381\n",
       "collide        -1.223941  1.223941\n",
       "counterexample -1.222887  1.222887\n",
       "rioter         -1.220632  1.220632\n",
       "defense         1.211632  1.211632\n",
       "makeup         -1.209765  1.209765\n",
       "awareness      -1.207143  1.207143"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tf_feat04 = pd.DataFrame(data=lr4.coef_.T, index=cvec.get_feature_names())\n",
    "lr_tf_feat04.columns = ['coef_']\n",
    "lr_tf_feat04['abs_coef'] = np.abs(lr_tf_feat04['coef_'])\n",
    "lr_tf_feat04.sort_values(by='abs_coef', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longest</th>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain</th>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>progressed</th>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watching</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>particulate</th>\n",
       "      <td>-0.001062</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refuse</th>\n",
       "      <td>-0.001032</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obstacle</th>\n",
       "      <td>-0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognise</th>\n",
       "      <td>-0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reclaim</th>\n",
       "      <td>-0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>victim</th>\n",
       "      <td>-0.000997</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrarian</th>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eminescu</th>\n",
       "      <td>-0.000873</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomy</th>\n",
       "      <td>-0.000873</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emission</th>\n",
       "      <td>-0.000873</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplier</th>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consultant</th>\n",
       "      <td>-0.000799</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versatile</th>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communist</th>\n",
       "      <td>-0.000746</td>\n",
       "      <td>0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insist</th>\n",
       "      <td>-0.000609</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nightmare</th>\n",
       "      <td>-0.000607</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addicted</th>\n",
       "      <td>-0.000564</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>send</th>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>given</th>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statement</th>\n",
       "      <td>-0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hardware</th>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>-0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leisure</th>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinier</th>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linking</th>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>untrue</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef_  abs_coef\n",
       "longest     -0.001130  0.001130\n",
       "contain      0.001122  0.001122\n",
       "progressed   0.001108  0.001108\n",
       "watching     0.001065  0.001065\n",
       "particulate -0.001062  0.001062\n",
       "refuse      -0.001032  0.001032\n",
       "obstacle    -0.000997  0.000997\n",
       "recognise   -0.000997  0.000997\n",
       "reclaim     -0.000997  0.000997\n",
       "victim      -0.000997  0.000997\n",
       "contrarian   0.000900  0.000900\n",
       "eminescu    -0.000873  0.000873\n",
       "autonomy    -0.000873  0.000873\n",
       "emission    -0.000873  0.000873\n",
       "supplier     0.000804  0.000804\n",
       "consultant  -0.000799  0.000799\n",
       "versatile    0.000759  0.000759\n",
       "communist   -0.000746  0.000746\n",
       "insist      -0.000609  0.000609\n",
       "nightmare   -0.000607  0.000607\n",
       "addicted    -0.000564  0.000564\n",
       "send         0.000545  0.000545\n",
       "given        0.000497  0.000497\n",
       "statement   -0.000458  0.000458\n",
       "hardware     0.000450  0.000450\n",
       "linux       -0.000368  0.000368\n",
       "leisure     -0.000283  0.000283\n",
       "tinier       0.000184  0.000184\n",
       "linking     -0.000125  0.000125\n",
       "untrue       0.000081  0.000081"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tf_feat04.sort_values(by='abs_coef', ascending=False).tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5 - Log Reg, custom stop words, GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "cvec = CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "lr5 = LogisticRegression()\n",
    "\n",
    "pipe5 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('lr5', lr5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11223 features in the model.\n",
      "train score: 0.9598246895544192\n",
      "test score: 0.7817518248175183\n"
     ]
    }
   ],
   "source": [
    "# baseline Logistic model\n",
    "\n",
    "pipe5.fit(X_train, y_train)\n",
    "print(\"There are {} features in the model.\".format(len(cvec.get_feature_names())))\n",
    "print('train score:', pipe5.score(X_train, y_train))\n",
    "print('test score:', pipe5.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Intercept: [-0.031114]\n",
      "Logistic Regression Coefficient: [[ 0.19954085 -0.00722808 -0.00065491 ... -0.15415459  0.35349915\n",
      "   0.17640627]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Intercept: {lr5.intercept_}')\n",
    "print(f'Logistic Regression Coefficient: {lr5.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   21.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.9 s, sys: 355 ms, total: 36.3 s\n",
      "Wall time: 25.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=10000,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_features': [5000, 10000, 20000],\n",
       "                         'lr__C': array([1.00000000e-10, 1.29154967e-09, 1.66810054e-08, 2.15443469e-07,\n",
       "       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n",
       "       7.74263683e-02, 1.00000000e+00]),\n",
       "                         'lr__penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# gridsearchCV tests cross-validation for the parameters\n",
    "# pipe\n",
    "\n",
    "params = {\n",
    "#     'cvec__stop_words': [stop_words], \n",
    "    'cvec__max_features': [5000, 10000, 20000], \n",
    "#     'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "    'lr__penalty': ['l1', 'l2'], \n",
    "    'lr__C': np.logspace(-10, 0, 10)\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3, verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analyzer', 'binary', 'decode_error', 'dtype', 'encoding', 'input', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'preprocessor', 'stop_words', 'strip_accents', 'token_pattern', 'tokenizer', 'vocabulary'])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs.best_score_ 0.7772096420745069\n",
      "gs.best_params_ {'cvec__max_features': 10000, 'lr__C': 1.0, 'lr__penalty': 'l2'}\n",
      "gs.score(X_test, y_test) 0.7846715328467153\n"
     ]
    }
   ],
   "source": [
    "print('gs.best_score_', gs.best_score_)\n",
    "print('gs.best_params_', gs.best_params_)\n",
    "print('gs.score(X_test, y_test)', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "# stratify y just in case\n",
    "# test_size : default = 0.25\n",
    "# shuffle: default = True\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size = 0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4655,), (822,), (4655,), (822,))"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 6 - RF, standard stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9950590762620838\n",
      "test score: 0.7749391727493917\n"
     ]
    }
   ],
   "source": [
    "cvec6 = CountVectorizer(analyzer = \"word\",                        \n",
    "                         tokenizer = None, \n",
    "                         preprocessor = None,\n",
    "                         stop_words = \"english\", \n",
    "                         max_features = 10000)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "pipe6 = Pipeline([\n",
    "    ('cve6', cvec6),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "pipe6.fit(X_train2, y_train2)\n",
    "print(\"There are {} features in the model.\".format(len(cvec6.get_feature_names())))\n",
    "print('train score:', pipe6.score(X_train2, y_train2))\n",
    "print('test score:', pipe6.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 7 - RF, custom stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9952738990332975\n",
      "test score: 0.7907542579075426\n"
     ]
    }
   ],
   "source": [
    "# using additional stop words\n",
    "\n",
    "cvec7 = CountVectorizer(analyzer = \"word\",                        \n",
    "                         tokenizer = None, \n",
    "                         preprocessor = None,\n",
    "                         stop_words = stop_words, \n",
    "                         max_features = 10000)\n",
    "rf2 = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "pipe7 = Pipeline([\n",
    "    ('cvec7', cvec7),\n",
    "    ('rf2', rf2)\n",
    "])\n",
    "\n",
    "pipe7.fit(X_train2, y_train2)\n",
    "print(\"There are {} features in the model.\".format(len(cvec7.get_feature_names())))\n",
    "print('train score:', pipe7.score(X_train2, y_train2))\n",
    "print('test score:', pipe7.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feat = cvec7.get_feature_names()\n",
    "rf_feat_import = rf.feature_importances_\n",
    "\n",
    "df_rf_frame = pd.DataFrame(data=rf_feat_import, index=rf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eloquent</th>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark</th>\n",
       "      <td>0.008860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nailed</th>\n",
       "      <td>0.008719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>0.005255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powder</th>\n",
       "      <td>0.005235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.004331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kanye</th>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>0.004108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enforcing</th>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.003956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentality</th>\n",
       "      <td>0.003710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogma</th>\n",
       "      <td>0.003665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terug</th>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hahaha</th>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solace</th>\n",
       "      <td>0.003461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newest</th>\n",
       "      <td>0.003347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donators</th>\n",
       "      <td>0.003344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>limelight</th>\n",
       "      <td>0.003285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stint</th>\n",
       "      <td>0.003218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinfingers</th>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.003050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onshore</th>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.002902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vuvuvu</th>\n",
       "      <td>0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>0.002844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grain</th>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0.002593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "eloquent      0.036400\n",
       "mark          0.008860\n",
       "nailed        0.008719\n",
       "period        0.005255\n",
       "powder        0.005235\n",
       "year          0.004411\n",
       "good          0.004331\n",
       "kanye         0.004191\n",
       "neighborhood  0.004108\n",
       "enforcing     0.004082\n",
       "country       0.004058\n",
       "climate       0.003956\n",
       "mentality     0.003710\n",
       "dogma         0.003665\n",
       "terug         0.003528\n",
       "hahaha        0.003463\n",
       "solace        0.003461\n",
       "newest        0.003347\n",
       "donators      0.003344\n",
       "limelight     0.003285\n",
       "stint         0.003218\n",
       "thinfingers   0.003202\n",
       "article       0.003050\n",
       "onshore       0.002939\n",
       "water         0.002902\n",
       "vuvuvu        0.002896\n",
       "cost          0.002844\n",
       "low           0.002620\n",
       "grain         0.002609\n",
       "company       0.002593"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_frame.sort_values(by=0, ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feat = cvec7.get_feature_names()\n",
    "rf_feat_imp = rf2.feature_importances_\n",
    "\n",
    "df_rf_feat01 = pd.DataFrame(data=rf_feat_imp, index=rf_feat)\n",
    "\n",
    "df_rf_feat01.columns = ['feature_importances_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importances_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elon</th>\n",
       "      <td>0.031665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musk</th>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mar</th>\n",
       "      <td>0.009240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0.005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.004769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.003911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>0.003708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>0.003708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.003658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meme</th>\n",
       "      <td>0.003486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesla</th>\n",
       "      <td>0.003252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>0.003233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralink</th>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil</th>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grime</th>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar</th>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>0.002887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gif</th>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>0.002714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.002701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0.002668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.002648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature_importances_\n",
       "elon                    0.031665\n",
       "musk                    0.009600\n",
       "mar                     0.009240\n",
       "power                   0.005880\n",
       "year                    0.005291\n",
       "people                  0.004987\n",
       "need                    0.004769\n",
       "country                 0.004327\n",
       "energy                  0.003972\n",
       "water                   0.003911\n",
       "stock                   0.003708\n",
       "just                    0.003708\n",
       "like                    0.003658\n",
       "climate                 0.003615\n",
       "meme                    0.003486\n",
       "article                 0.003298\n",
       "tesla                   0.003252\n",
       "lot                     0.003233\n",
       "neuralink               0.003231\n",
       "thing                   0.003202\n",
       "oil                     0.003080\n",
       "grime                   0.003059\n",
       "solar                   0.002953\n",
       "government              0.002887\n",
       "gif                     0.002786\n",
       "right                   0.002737\n",
       "cost                    0.002714\n",
       "know                    0.002701\n",
       "car                     0.002668\n",
       "think                   0.002648"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_feat01.sort_values(by='feature_importances_', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importances_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>revolves</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revved</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cased</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cascade</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhetorical</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhythm</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carved</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartoonish</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>richmond</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caribbean</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enforced</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kruger</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carcass</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caravan</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>righteousness</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capybara</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rigid</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rigorously</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breed</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature_importances_\n",
       "revolves                        0.0\n",
       "revved                          0.0\n",
       "cased                           0.0\n",
       "cascade                         0.0\n",
       "rhetorical                      0.0\n",
       "rhythm                          0.0\n",
       "carved                          0.0\n",
       "cartoonish                      0.0\n",
       "richmond                        0.0\n",
       "ridge                           0.0\n",
       "caribbean                       0.0\n",
       "enforced                        0.0\n",
       "kruger                          0.0\n",
       "carcass                         0.0\n",
       "caravan                         0.0\n",
       "righteousness                   0.0\n",
       "capybara                        0.0\n",
       "rigid                           0.0\n",
       "rigorously                      0.0\n",
       "breed                           0.0"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_feat01.sort_values(by='feature_importances_', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 8 - RF, custom stop words, n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9922084246408571\n",
      "test score: 0.7489051094890511\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer & Random forest using additional stop words and 1 - 3 n-grams\n",
    "\n",
    "tf = TfidfVectorizer(analyzer = \"word\", \n",
    "                       tokenizer = None, \n",
    "                       preprocessor = None,\n",
    "                       stop_words = stop_words, \n",
    "                       max_features = 10000, \n",
    "                       ngram_range = (1, 3)\n",
    "                      )\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tf', tf),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"There are {} features in the model.\".format(len(tf.get_feature_names())))\n",
    "print('train score:', pipe.score(X_train, y_train))\n",
    "print('test score:', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feat = cvec.get_feature_names()\n",
    "rf_feat_imp = rf.feature_importances_\n",
    "\n",
    "df_rf_feat02 = pd.DataFrame(data=rf_feat_imp, index=rf_feat)\n",
    "\n",
    "df_rf_feat02.columns = ['feature_importances_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importances_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elon</th>\n",
       "      <td>0.031368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mar</th>\n",
       "      <td>0.010007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musk</th>\n",
       "      <td>0.008902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.005263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0.005102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0.004461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.004336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.003939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.003923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar</th>\n",
       "      <td>0.003523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.003413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>0.003379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meme</th>\n",
       "      <td>0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost</th>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil</th>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralink</th>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesla</th>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>0.002768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.002752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.002620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grime</th>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.002608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gif</th>\n",
       "      <td>0.002530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.002529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem</th>\n",
       "      <td>0.002512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>0.002507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.002484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>0.002484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>0.002473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>california</th>\n",
       "      <td>0.002451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>literally</th>\n",
       "      <td>0.002397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elon musk</th>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0.002269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>0.002263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>0.002248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.002171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decade</th>\n",
       "      <td>0.002153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spacex</th>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "      <td>0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.002065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.002044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas</th>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature_importances_\n",
       "elon                    0.031368\n",
       "mar                     0.010007\n",
       "musk                    0.008902\n",
       "power                   0.006244\n",
       "year                    0.005263\n",
       "people                  0.005102\n",
       "country                 0.004461\n",
       "energy                  0.004336\n",
       "need                    0.003939\n",
       "water                   0.003923\n",
       "just                    0.003863\n",
       "stock                   0.003835\n",
       "solar                   0.003523\n",
       "like                    0.003413\n",
       "lot                     0.003379\n",
       "article                 0.003352\n",
       "meme                    0.003264\n",
       "cost                    0.003242\n",
       "oil                     0.003114\n",
       "thing                   0.003077\n",
       "neuralink               0.002985\n",
       "tesla                   0.002939\n",
       "government              0.002768\n",
       "climate                 0.002752\n",
       "new                     0.002620\n",
       "grime                   0.002615\n",
       "state                   0.002608\n",
       "gif                     0.002530\n",
       "right                   0.002529\n",
       "problem                 0.002512\n",
       "change                  0.002507\n",
       "work                    0.002484\n",
       "wind                    0.002484\n",
       "lol                     0.002473\n",
       "california              0.002451\n",
       "car                     0.002428\n",
       "literally               0.002397\n",
       "twitter                 0.002321\n",
       "elon musk               0.002313\n",
       "company                 0.002269\n",
       "know                    0.002263\n",
       "land                    0.002248\n",
       "think                   0.002171\n",
       "decade                  0.002153\n",
       "spacex                  0.002125\n",
       "issue                   0.002098\n",
       "make                    0.002092\n",
       "use                     0.002065\n",
       "money                   0.002044\n",
       "gas                     0.002037"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf_feat02.sort_values(by='feature_importances_', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 9 - RF, custom stop words, GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "cvec = CountVectorizer(analyzer = \"word\",                        \n",
    "                         tokenizer = None, \n",
    "                         preprocessor = None,\n",
    "                         stop_words = stop_words, \n",
    "                         max_features = 10000)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 features in the model.\n",
      "train score: 0.9952738990332975\n",
      "test score: 0.7907542579075426\n"
     ]
    }
   ],
   "source": [
    "# baseline Random forest\n",
    "\n",
    "pipe.fit(X_train2, y_train2)\n",
    "print(\"There are {} features in the model.\".format(len(cvec.get_feature_names())))\n",
    "print('train score:', pipe.score(X_train2, y_train2))\n",
    "print('test score:', pipe.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.8 s, sys: 1.88 s, total: 1min\n",
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=10000,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=frozenset({'a',\n",
       "                                                                              'about',\n",
       "                                                                              'above',\n",
       "                                                                              'across',\n",
       "                                                                              'a...\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'cvec__max_features': [5000, 10000, 20000],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'rf__max_depth': [None, 10, 20],\n",
       "                         'rf__n_estimators': [10, 20, 30]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# gridsearchCV tests cross-validation for the parameters\n",
    "# pipe\n",
    "\n",
    "params = {\n",
    "#     'cvec__stop_words': [None, 'english'], \n",
    "    'cvec__max_features': [5000, 10000, 20000], \n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "    'rf__n_estimators': [10, 20, 30],\n",
    "    'rf__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3, verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs.best_score_ 0.7560262965668372\n",
      "gs.best_params_ {'cvec__max_features': 20000, 'cvec__ngram_range': (1, 2), 'rf__max_depth': None, 'rf__n_estimators': 30}\n",
      "gs.score(X_test, y_test) 0.772992700729927\n"
     ]
    }
   ],
   "source": [
    "print('gs.best_score_', gs.best_score_)\n",
    "print('gs.best_params_', gs.best_params_)\n",
    "print('gs.score(X_test, y_test)', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       body  target  word_count  char_count  sentence_count  avg_word_length  \\\n",
       "0  removed        1           2           7               1              3.5   \n",
       "\n",
       "   avg_sentence_length  \n",
       "0                  2.0  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = df.body\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>removed</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the name like rex not ash nickname little vide...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>4.710526</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>probably the demand insane</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these image emanate 2006 2014 and 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not having all the crazed medium attention act...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lame</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>look like bought some hair</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>itt most people think take this shit</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dude whoa feel out the loop when did the last ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>would say most like howard hughes robert house</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  target  word_count  \\\n",
       "0                                           removed        1           2   \n",
       "1  the name like rex not ash nickname little vide...       1          38   \n",
       "2                        probably the demand insane        1           5   \n",
       "3            these image emanate 2006 2014 and 2020        1           8   \n",
       "4  not having all the crazed medium attention act...       1          11   \n",
       "5                                              lame        1           2   \n",
       "6                        look like bought some hair        1           6   \n",
       "7              itt most people think take this shit        1           8   \n",
       "8  dude whoa feel out the loop when did the last ...       1          18   \n",
       "9    would say most like howard hughes robert house        1           9   \n",
       "\n",
       "   char_count  sentence_count  avg_word_length  avg_sentence_length  \n",
       "0           7               1         3.500000                  2.0  \n",
       "1         179               1         4.710526                 38.0  \n",
       "2          23               1         4.600000                  5.0  \n",
       "3          32               1         4.000000                  8.0  \n",
       "4          60               1         5.454545                 11.0  \n",
       "5           4               1         2.000000                  2.0  \n",
       "6          22               1         3.666667                  6.0  \n",
       "7          30               1         3.750000                  8.0  \n",
       "8          72               1         4.000000                 18.0  \n",
       "9          39               1         4.333333                  9.0  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "# stratify y just in case\n",
    "# test_size : default = 0.25\n",
    "# shuffle: default = True\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 10 - Bayes, MultinomialNB classifier, custom stop words, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipeline, using mnb\n",
    "\n",
    "# initialize\n",
    "cvec = CountVectorizer(stop_words = stop_words)\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "pipe10 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('mnb', mnb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive Bayes classifier\n",
      "Train score: 0.8654, Test score 0.7175\n",
      "Number of features: 11324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "mnb_model = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    MultinomialNB()\n",
    ")\n",
    "cv_scores = cross_val_score(mnb_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "mnb_model.fit(X_train, y_train)\n",
    "y_pred = mnb_model.predict(X_test)\n",
    "print('Multinomial naive Bayes classifier')\n",
    "print('Train score: {}, Test score {}'.format(round(cv_scores.mean(), 4), round(roc_auc_score(y_test, y_pred), 4)))\n",
    "print('Number of features: {}'.format(len(mnb_model.named_steps.countvectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive Bayes classifier\n",
      "Train score: 0.8654, Test score 0.7175\n",
      "Number of features: 11324\n"
     ]
    }
   ],
   "source": [
    "#code help from https://www.programcreek.com/python/example/85919/sklearn.naive_bayes.MultinomialNB\n",
    "\n",
    "# Fit and predict a multinomial naive Bayes classifier (suits with discrete features)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_model = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    MultinomialNB()\n",
    ")\n",
    "cv_scores = cross_val_score(mnb_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "mnb_model.fit(X_train, y_train)\n",
    "y_pred = mnb_model.predict(X_test)\n",
    "print('Multinomial naive Bayes classifier')\n",
    "print('Train score: {}, Test score {}'.format(round(cv_scores.mean(), 4), round(roc_auc_score(y_test, y_pred), 4)))\n",
    "print('Number of features: {}'.format(len(mnb_model.named_steps.countvectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'cvec__max_df': 0.5, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None, 'tfidf': None}\n",
      "Train score: 0.8654, Test score 0.7993\n",
      "Number of features: 11586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  7.9min finished\n"
     ]
    }
   ],
   "source": [
    "#code help from https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/\n",
    "# Explore parameters for vectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('tfidf', None),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = dict(\n",
    "    cvec__stop_words = [None, 'english'],\n",
    "    cvec__max_df = (0.5, 0.75, 1.0),\n",
    "    cvec__ngram_range = [(1, 1), (2, 2)],\n",
    "    tfidf = [None, TfidfTransformer(use_idf=True), TfidfTransformer(use_idf=False)]\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, scoring='roc_auc', iid=False, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Best params: {}\".format(gs.best_params_))\n",
    "print('Train score: {}, Test score {}'.format(round(gs.best_score_, 4), round(gs.best_estimator_.score(X_test, y_test), 4)))\n",
    "print('Number of features: {}'.format(len(gs.best_estimator_.named_steps.cvec.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'cvec__stop_words': 'english', 'mnb__alpha': 0.24210526315789474, 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)}\n",
      "Train score: 0.8664, Test score 0.7927\n",
      "Number of features: 11324\n"
     ]
    }
   ],
   "source": [
    "#code help from https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/\n",
    "# Tune hyperparameter for multinomial naive Bayes\n",
    "params = dict(\n",
    "    cvec__stop_words = ['english'],\n",
    "    tfidf = [TfidfTransformer(use_idf=True)],\n",
    "    mnb__alpha = np.linspace(0.1, 1.0, 20)\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, scoring='roc_auc', iid=False, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Best params: {}\".format(gs.best_params_))\n",
    "print('Train score: {}, Test score {}'.format(round(gs.best_score_, 4), round(gs.best_estimator_.score(X_test, y_test), 4)))\n",
    "print('Number of features: {}'.format(len(gs.best_estimator_.named_steps.cvec.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict /r/elonmusk</th>\n",
       "      <th>predict /r/Futurology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual /r/elonmusk</th>\n",
       "      <td>876</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual /r/Futurology</th>\n",
       "      <td>210</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      predict /r/elonmusk  predict /r/Futurology\n",
       "actual /r/elonmusk                    876                     68\n",
       "actual /r/Futurology                  210                    216"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = mnb_model.predict(X_test)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "            columns=['predict /r/elonmusk', 'predict /r/Futurology'],\n",
    "            index=['actual /r/elonmusk', 'actual /r/Futurology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7971\n",
      "Misclassification rate: 0.2029\n",
      "Precision: 0.7606\n",
      "Recall: 0.507\n",
      "Specificity: 0.928\n"
     ]
    }
   ],
   "source": [
    "#code help from https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# Examine some classification metrics \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('Accuracy: {}'.format(round((tp+tn)/(tp+fp+tn+fn),4)))\n",
    "print('Misclassification rate: {}'.format(round((fp+fn)/(tp+fp+tn+fn),4)))\n",
    "print('Precision: {}'.format(round(tp/(tp+fp),4)))\n",
    "print('Recall: {}'.format(round(tp/(tp+fn),4)))\n",
    "print('Specificity: {}'.format(round(tn/(tn+fp),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our model correctly predicts 79.71% of observations.\n",
    "- Among posts that our model predicted to be in /r/Futurology, we have 76.06% of them correctly classified.\n",
    "- Among posts that are in /r/Futurology, our model has 51% of them correctly classified.\n",
    "- Among posts that are in /r/elonmusk, our model has 92.8% of them correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average the y_test_hat vectors to see if we can improve the score\n",
    "#y_test_hat_agg = sum(df.loc['y_test_hat',:])\n",
    "#y_test_hat = np.round(y_test_hat_agg/df.shape[1])\n",
    "#print(\"The accuracy score of the average test solutions is {:.2f}%.\".format(accuracy_score(y_test,y_test_hat)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine incorrectly classified posts\n",
    "df_pred = pd.DataFrame({\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "# Posts incorrectly predicted to be in /r/relationship_advice\n",
    "for i in df_pred[(df_pred.y_test - df_pred.y_pred) > 0]['X_test']:\n",
    "    print(i)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 11 - Bayes, BernoulliNB classifier, custom stop words, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipeline, using mnb\n",
    "\n",
    "# initialize\n",
    "cvec = CountVectorizer(stop_words = stop_words)\n",
    "bnb = BernoulliNB(alpha=1.0, binarize=0.0)\n",
    "\n",
    "pipe11 = Pipeline([\n",
    "    ('cvec', cvec),\n",
    "    ('bnb', bnb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11391 features in the model.\n",
      "train score: 1.0\n",
      "test score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# baseline BernoulliNB model\n",
    "\n",
    "pipe11.fit(X_train3, y_train3)\n",
    "print(\"There are {} features in the model.\".format(len(cvec.get_feature_names())))\n",
    "print('train score:', pipe11.score(X_train3, y_train3))\n",
    "print('test score:', pipe11.score(X_test3, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'binarize', 'class_prior', 'fit_prior'])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 s, sys: 30.7 ms, total: 2 s\n",
      "Wall time: 2.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=frozenset({'a',\n",
       "                                                                              'about',\n",
       "                                                                              'above',\n",
       "                                                                              'across',\n",
       "                                                                              'af...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('bnb',\n",
       "                                        BernoulliNB(alpha=1.0, binarize=0.0,\n",
       "                                                    class_prior=None,\n",
       "                                                    fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'bnb__alpha': [0, 0.25, 0.5, 0.75, 1],\n",
       "                         'cvec__max_features': [10000],\n",
       "                         'cvec__ngram_range': [(1, 1)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# gridsearchCV tests cross-validation for the parameters\n",
    "\n",
    "params = {\n",
    "#     'cvec__stop_words': [None, 'english'], \n",
    "#     'cvec__max_features': [5000, 10000, 20000], \n",
    "#     'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "    'cvec__max_features': [10000], \n",
    "    'cvec__ngram_range': [(1, 1)], \n",
    "    'bnb__alpha': [0, 0.25, 0.5, 0.75, 1]\n",
    "    # min_df\n",
    "    # max_df\n",
    "    #binarizer__threshold': np.logspace(0, 5, 20) #use for BernoulliNB\n",
    "}\n",
    "gs2 = GridSearchCV(pipe11, param_grid=params, cv=3, verbose=1)\n",
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli naive Bayes classifier\n",
      "Train score: 0.8541, Test score 0.768\n",
      "Number of features: 11324\n"
     ]
    }
   ],
   "source": [
    "#code help from https://towardsdatascience.com/understanding-data-science-classification-metrics-in-scikit-learn-in-python-3bc336865019\n",
    "#Tuning model\n",
    "\n",
    "bnb_model = make_pipeline(\n",
    "    CountVectorizer(stop_words='english'),\n",
    "    BernoulliNB()\n",
    ")\n",
    "cv_scores = cross_val_score(bnb_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "bnb_model.fit(X_train, y_train)\n",
    "y_pred = bnb_model.predict(X_test)\n",
    "print('Bernoulli naive Bayes classifier')\n",
    "print('Train score: {}, Test score {}'.format(round(cv_scores.mean(), 4), round(roc_auc_score(y_test, y_pred), 4)))\n",
    "print('Number of features: {}'.format(len(bnb_model.named_steps.countvectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs2.best_score_ 0.7888970051132214\n",
      "gs2.best_params_ {'bnb__alpha': 1, 'cvec__max_features': 10000, 'cvec__ngram_range': (1, 1)}\n",
      "gs2.score(X_test, y_test) 0.7394160583941606\n"
     ]
    }
   ],
   "source": [
    "print('gs2.best_score_', gs2.best_score_)\n",
    "print('gs2.best_params_', gs2.best_params_)\n",
    "print('gs2.score(X_test, y_test)', gs2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.79457444, -7.62778779, -7.62778779, ..., -7.22232268,\n",
       "        -7.62778779, -7.62778779],\n",
       "       [-0.69314718, -0.69314718, -0.69314718, ..., -0.69314718,\n",
       "        -0.69314718, -0.69314718]])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.feature_log_prob_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Function to run gridsearch on anything we want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code help from https://hpc-carpentry.github.io/hpc-python/05-functions/\n",
    "#code help from https://medium.com/@kadirmalak/how-to-pipe-chain-functions-in-python-137c36150c1\n",
    "#code help from https://medium.com/@ManningBooks/function-pipelines-for-mapping-complex-transformations-66b09bf29c68\n",
    "#https://medium.com/@yanhann10/a-brief-view-of-machine-learning-pipeline-in-python-5f50b941fca8\n",
    "\n",
    "def create_pipline(items, use_params, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Add a pipe, add a param !\n",
    "    pipe_items = {\n",
    "        'cv': CountVectorizer(),\n",
    "        'tv': TfidfVectorizer(),\n",
    "        'hv': HashingVectorizer(),\n",
    "\n",
    "        'ss' : StandardScaler(),\n",
    "        'pf' : PolynomialFeatures(),\n",
    "\n",
    "        'lr' : LogisticRegression(),\n",
    "        'bnb' : BernoulliNB(),\n",
    "        'mnb' : MultinomialNB(),\n",
    "        'rf' : RandomForestClassifier(),\n",
    "        'gb' : GradientBoostingClassifier(),\n",
    "        'ab' : AdaBoostClassifier(),\n",
    "        'svc' : SVC(),\n",
    "        'knn' : KNeighborsClassifier()\n",
    "    }\n",
    "\n",
    "    # Include at least one param for each pipe item\n",
    "    param_items = {\n",
    "        'cv' : {\n",
    "            'cv__stop_words' : [None, 'english'],\n",
    "            'cv__ngram_range' : [(1,1), (1,2)],\n",
    "            'cv__max_df' : [1.0, 0.95],\n",
    "            'cv__min_df' : [1],\n",
    "            'cv__max_features' : [2000, 2250, 2500, 2750]\n",
    "        },\n",
    "        'tv' : {\n",
    "            'tv__stop_words' : [None, 'english'],\n",
    "            'tv__ngram_range' : [(1,1), (1,2)],\n",
    "            'tv__max_df' : [1.0, 0.95],\n",
    "            'tv__min_df' : [1, 2],\n",
    "            'tv__max_features' : [2000, 2250, 2500, 2750]\n",
    "        },\n",
    "        'hv' : {\n",
    "            'hv__stop_words' : [None, 'english'],\n",
    "            'hv__ngram_range' : [(1,1), (1,2)]\n",
    "        },\n",
    "        'ss' : {\n",
    "            'ss__with_mean' : [False]\n",
    "        },\n",
    "        'pf' : {\n",
    "            'pf__degree' : [2]\n",
    "        },\n",
    "        'lr' : {\n",
    "            'lr__C' : [1, .05],\n",
    "            'lr__penalty' : ['l2']\n",
    "        },\n",
    "        'bnb' : {\n",
    "            'bnb__alpha' : [1.0, 1.5, 1.8, 2.0]\n",
    "        },\n",
    "        'mnb' : {\n",
    "            'mnb__alpha' : [0.8, 1.0, 1.2]\n",
    "        },\n",
    "        'rf' : {\n",
    "            'rf__n_estimators' : [8, 10, 15]\n",
    "        },\n",
    "        'gb' : {\n",
    "            'gb__n_estimators' : [80, 100, 120]\n",
    "        },\n",
    "        'ab' : {\n",
    "            'ab__n_estimators' : [75, 50, 125]\n",
    "        },\n",
    "        'svc' : {\n",
    "            'svc__kernel' : ['linear','poly']\n",
    "        },\n",
    "        'knn' : {\n",
    "            'knn__n_neighbors' : [25,35,45]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create the parameters for GridSearch\n",
    "    params = dict()\n",
    "    if use_params:\n",
    "        for i in items:\n",
    "            for p in param_items[i]:\n",
    "                params[p] = param_items[i][p]\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipe_list = [(i,pipe_items[i]) for i in items]\n",
    "    print(\"Using:\")\n",
    "    for p in pipe_list:\n",
    "        print(\"\\t\" + str(p[1]).split('(')[0])\n",
    "    pipe = Pipeline(pipe_list)\n",
    "\n",
    "    # Grid search\n",
    "    gs = GridSearchCV(pipe, param_grid=params, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Print the results\n",
    "    train_params = gs.best_params_\n",
    "    train_score = gs.best_score_\n",
    "    y_test_hat = gs.predict(X_test)\n",
    "    test_score = gs.score(X_test, y_test)\n",
    "\n",
    "    for k in train_params:\n",
    "        print(\"{}: {}\".format(k,train_params[k]))\n",
    "\n",
    "    print(\"Train score: {} Test score {}\".format(train_score, test_score))\n",
    "    print(\"\")\n",
    "\n",
    "    return train_score, test_score, y_test_hat, train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\tCountVectorizer\n",
      "\tLogisticRegression\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv__max_df: 1.0\n",
      "cv__max_features: 2750\n",
      "cv__min_df: 1\n",
      "cv__ngram_range: (1, 1)\n",
      "cv__stop_words: None\n",
      "lr__C: 1\n",
      "lr__penalty: l2\n",
      "Train score: 0.7857280451410806 Test score 0.7824817518248175\n",
      "\n",
      "Using:\n",
      "\tCountVectorizer\n",
      "\tBernoulliNB\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 640 out of 640 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnb__alpha: 2.0\n",
      "cv__max_df: 1.0\n",
      "cv__max_features: 2750\n",
      "cv__min_df: 1\n",
      "cv__ngram_range: (1, 1)\n",
      "cv__stop_words: english\n",
      "Train score: 0.6985641508930714 Test score 0.6744525547445256\n",
      "\n",
      "Using:\n",
      "\tCountVectorizer\n",
      "\tMultinomialNB\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 480 out of 480 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv__max_df: 1.0\n",
      "cv__max_features: 2750\n",
      "cv__min_df: 1\n",
      "cv__ngram_range: (1, 1)\n",
      "cv__stop_words: None\n",
      "mnb__alpha: 1.2\n",
      "Train score: 0.7786703059292122 Test score 0.775912408759124\n",
      "\n",
      "Using:\n",
      "\tTfidfVectorizer\n",
      "\tLogisticRegression\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 640 out of 640 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr__C: 1\n",
      "lr__penalty: l2\n",
      "tv__max_df: 1.0\n",
      "tv__max_features: 2000\n",
      "tv__min_df: 1\n",
      "tv__ngram_range: (1, 1)\n",
      "tv__stop_words: None\n",
      "Train score: 0.7774481301362354 Test score 0.7875912408759124\n",
      "\n",
      "Using:\n",
      "\tTfidfVectorizer\n",
      "\tBernoulliNB\n",
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1280 out of 1280 | elapsed:  8.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnb__alpha: 2.0\n",
      "tv__max_df: 1.0\n",
      "tv__max_features: 2750\n",
      "tv__min_df: 2\n",
      "tv__ngram_range: (1, 1)\n",
      "tv__stop_words: english\n",
      "Train score: 0.6985647436068411 Test score 0.6722627737226278\n",
      "\n",
      "Using:\n",
      "\tTfidfVectorizer\n",
      "\tMultinomialNB\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 960 out of 960 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb__alpha: 0.8\n",
      "tv__max_df: 1.0\n",
      "tv__max_features: 2250\n",
      "tv__min_df: 1\n",
      "tv__ngram_range: (1, 2)\n",
      "tv__stop_words: english\n",
      "Train score: 0.7745290148208077 Test score 0.7766423357664234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#code help from https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976\n",
    "#Decide what to put into the pipline, grid searh, and save the \"best\" for each grid search\n",
    "use_params = True\n",
    "vects = ['cvec, cvec2, cvec3, cvec5, cvec6, cvec7, tf']\n",
    "models = ['lr','bnb', 'mnb','rf']\n",
    "other = ['pf','ss']\n",
    "\n",
    "# After some initial tests, these seem like the best to pursue further\n",
    "vects = ['cv','tv']\n",
    "models = ['lr','bnb', 'mnb']\n",
    "other = []\n",
    "\n",
    "model_solns = {}\n",
    "idx = 0\n",
    "for v in vects:\n",
    "    for i in range(len(other)+1):\n",
    "        for o in list(combinations(other, i)):\n",
    "            for m in models:\n",
    "                idx += 1\n",
    "                pipe_items = [v]\n",
    "                pipe_items.extend(list(o))\n",
    "                pipe_items.append(m)\n",
    "                [train_score, test_score, y_test_hat, best_params] = create_pipline(pipe_items, use_params,\n",
    "                                                                        X_train, X_test,\n",
    "                                                                        y_train, y_test)\n",
    "                model_solns[idx] = {'vectorizer' : v, 'model': m, 'features': list(o),\n",
    "                                    'train_score': train_score, 'test_score': test_score,\n",
    "                                    'best_params': best_params, 'y_test_hat' : y_test_hat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:1000px;  /* 500px */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#changing output options\n",
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:1000px;  /* 500px */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vectorizer</th>\n",
       "      <td>tv</td>\n",
       "      <td>cv</td>\n",
       "      <td>tv</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lr</td>\n",
       "      <td>lr</td>\n",
       "      <td>mnb</td>\n",
       "      <td>mnb</td>\n",
       "      <td>bnb</td>\n",
       "      <td>bnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.777448</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>0.774529</td>\n",
       "      <td>0.77867</td>\n",
       "      <td>0.698564</td>\n",
       "      <td>0.698565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.787591</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.775912</td>\n",
       "      <td>0.674453</td>\n",
       "      <td>0.672263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params</th>\n",
       "      <td>{'lr__C': 1, 'lr__penalty': 'l2', 'tv__max_df'...</td>\n",
       "      <td>{'cv__max_df': 1.0, 'cv__max_features': 2750, ...</td>\n",
       "      <td>{'mnb__alpha': 0.8, 'tv__max_df': 1.0, 'tv__ma...</td>\n",
       "      <td>{'cv__max_df': 1.0, 'cv__max_features': 2750, ...</td>\n",
       "      <td>{'bnb__alpha': 2.0, 'cv__max_df': 1.0, 'cv__ma...</td>\n",
       "      <td>{'bnb__alpha': 2.0, 'tv__max_df': 1.0, 'tv__ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test_hat</th>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             4  \\\n",
       "vectorizer                                                  tv   \n",
       "model                                                       lr   \n",
       "features                                                    []   \n",
       "train_score                                           0.777448   \n",
       "test_score                                            0.787591   \n",
       "best_params  {'lr__C': 1, 'lr__penalty': 'l2', 'tv__max_df'...   \n",
       "y_test_hat   [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                             1  \\\n",
       "vectorizer                                                  cv   \n",
       "model                                                       lr   \n",
       "features                                                    []   \n",
       "train_score                                           0.785728   \n",
       "test_score                                            0.782482   \n",
       "best_params  {'cv__max_df': 1.0, 'cv__max_features': 2750, ...   \n",
       "y_test_hat   [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                                             6  \\\n",
       "vectorizer                                                  tv   \n",
       "model                                                      mnb   \n",
       "features                                                    []   \n",
       "train_score                                           0.774529   \n",
       "test_score                                            0.776642   \n",
       "best_params  {'mnb__alpha': 0.8, 'tv__max_df': 1.0, 'tv__ma...   \n",
       "y_test_hat   [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                             3  \\\n",
       "vectorizer                                                  cv   \n",
       "model                                                      mnb   \n",
       "features                                                    []   \n",
       "train_score                                            0.77867   \n",
       "test_score                                            0.775912   \n",
       "best_params  {'cv__max_df': 1.0, 'cv__max_features': 2750, ...   \n",
       "y_test_hat   [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                             2  \\\n",
       "vectorizer                                                  cv   \n",
       "model                                                      bnb   \n",
       "features                                                    []   \n",
       "train_score                                           0.698564   \n",
       "test_score                                            0.674453   \n",
       "best_params  {'bnb__alpha': 2.0, 'cv__max_df': 1.0, 'cv__ma...   \n",
       "y_test_hat   [1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                                             5  \n",
       "vectorizer                                                  tv  \n",
       "model                                                      bnb  \n",
       "features                                                    []  \n",
       "train_score                                           0.698565  \n",
       "test_score                                            0.672263  \n",
       "best_params  {'bnb__alpha': 2.0, 'tv__max_df': 1.0, 'tv__ma...  \n",
       "y_test_hat   [1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_df = pd.DataFrame(model_solns)\n",
    "best_df.sort_values(ascending=False, by='test_score',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vectorizer</th>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>cv</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lr</td>\n",
       "      <td>bnb</td>\n",
       "      <td>mnb</td>\n",
       "      <td>lr</td>\n",
       "      <td>bnb</td>\n",
       "      <td>mnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.785728</td>\n",
       "      <td>0.698564</td>\n",
       "      <td>0.77867</td>\n",
       "      <td>0.777448</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>0.774529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.674453</td>\n",
       "      <td>0.775912</td>\n",
       "      <td>0.787591</td>\n",
       "      <td>0.672263</td>\n",
       "      <td>0.776642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params</th>\n",
       "      <td>{'cv__max_df': 1.0, 'cv__max_features': 2750, ...</td>\n",
       "      <td>{'bnb__alpha': 2.0, 'cv__max_df': 1.0, 'cv__ma...</td>\n",
       "      <td>{'cv__max_df': 1.0, 'cv__max_features': 2750, ...</td>\n",
       "      <td>{'lr__C': 1, 'lr__penalty': 'l2', 'tv__max_df'...</td>\n",
       "      <td>{'bnb__alpha': 2.0, 'tv__max_df': 1.0, 'tv__ma...</td>\n",
       "      <td>{'mnb__alpha': 0.8, 'tv__max_df': 1.0, 'tv__ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             1  \\\n",
       "vectorizer                                                  cv   \n",
       "model                                                       lr   \n",
       "train_score                                           0.785728   \n",
       "test_score                                            0.782482   \n",
       "best_params  {'cv__max_df': 1.0, 'cv__max_features': 2750, ...   \n",
       "\n",
       "                                                             2  \\\n",
       "vectorizer                                                  cv   \n",
       "model                                                      bnb   \n",
       "train_score                                           0.698564   \n",
       "test_score                                            0.674453   \n",
       "best_params  {'bnb__alpha': 2.0, 'cv__max_df': 1.0, 'cv__ma...   \n",
       "\n",
       "                                                             3  \\\n",
       "vectorizer                                                  cv   \n",
       "model                                                      mnb   \n",
       "train_score                                            0.77867   \n",
       "test_score                                            0.775912   \n",
       "best_params  {'cv__max_df': 1.0, 'cv__max_features': 2750, ...   \n",
       "\n",
       "                                                             4  \\\n",
       "vectorizer                                                  tv   \n",
       "model                                                       lr   \n",
       "train_score                                           0.777448   \n",
       "test_score                                            0.787591   \n",
       "best_params  {'lr__C': 1, 'lr__penalty': 'l2', 'tv__max_df'...   \n",
       "\n",
       "                                                             5  \\\n",
       "vectorizer                                                  tv   \n",
       "model                                                      bnb   \n",
       "train_score                                           0.698565   \n",
       "test_score                                            0.672263   \n",
       "best_params  {'bnb__alpha': 2.0, 'tv__max_df': 1.0, 'tv__ma...   \n",
       "\n",
       "                                                             6  \n",
       "vectorizer                                                  tv  \n",
       "model                                                      mnb  \n",
       "train_score                                           0.774529  \n",
       "test_score                                            0.776642  \n",
       "best_params  {'mnb__alpha': 0.8, 'tv__max_df': 1.0, 'tv__ma...  "
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_df.loc[['vectorizer','model','train_score','test_score','best_params'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv__max_df': 1.0, 'cv__max_features': 2750, 'cv__min_df': 1, 'cv__ngram_range': (1, 1), 'cv__stop_words': None, 'lr__C': 1, 'lr__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(best_df.loc['best_params'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the average test solutions is 78.83%.\n"
     ]
    }
   ],
   "source": [
    "#code help from https://www.dataquest.io/blog/data-pipelines-tutorial/\n",
    "# Average the y_test_hat vectors to see if we can improve the score\n",
    "y_test_hat_agg = sum(best_df.loc['y_test_hat',:])\n",
    "y_test_hat = np.round(y_test_hat_agg/best_df.shape[1])\n",
    "print(\"The accuracy score of the average test solutions is {:.2f}%.\".format(accuracy_score(y_test,y_test_hat)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
